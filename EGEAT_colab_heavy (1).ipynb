{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62f01271",
   "metadata": {},
   "source": [
    "\n",
    "# EGEAT ‚Äî Exact Geometric Ensemble Adversarial Training (Colab-Heavy Reproduction)\n",
    "\n",
    "**Implements Algorithm¬†1 exactly** with Eq.¬†(11) (exact inner maximization), Eq.¬†(4) (geometric regularizer), and Eq.¬†(5) (weight‚Äëspace smoothing).  \n",
    "Datasets: **MNIST (Œµ=0.3)** and **CIFAR‚Äë10 (Œµ=8/255)**. DCGAN‚Äëinspired CNNs.  \n",
    "Training defaults (Sec.¬†V‚ÄëC): **K=5, Œª‚ÇÅ=0.1, Œª‚ÇÇ=0.05, batch=128, Adam(2e‚Äë4, Œ≤‚ÇÅ=0.5), epochs=100**.  \n",
    "Evaluations: Clean, FGSM, PGD‚Äë20; gradient similarity; loss surface; transferability; ablation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab20331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, math, random, time, copy, itertools\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SAVE_DIR = \"/content\" if os.path.exists(\"/content\") else \".\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "print(\"Device:\", device, \"| SAVE_DIR:\", SAVE_DIR)\n",
    "\n",
    "# ======================================\n",
    "# RESEARCH-GRADE VISUALIZATION SUITE üåå\n",
    "# ======================================\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import LightSource\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# --- Global Aesthetic Settings ---\n",
    "RESEARCH_THEME = {\n",
    "    \"figure.facecolor\": \"#0B0B0C\",\n",
    "    \"axes.facecolor\": \"#121212\",\n",
    "    \"axes.edgecolor\": \"#3C3C3C\",\n",
    "    \"axes.labelcolor\": \"#EEEEEE\",\n",
    "    \"xtick.color\": \"#B0B0B0\",\n",
    "    \"ytick.color\": \"#B0B0B0\",\n",
    "    \"text.color\": \"#FFFFFF\",\n",
    "    \"font.size\": 13,\n",
    "    \"axes.linewidth\": 1.1,\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.color\": \"#242424\",\n",
    "    \"grid.alpha\": 0.3,\n",
    "    \"figure.dpi\": 160,\n",
    "    \"savefig.dpi\": 400,\n",
    "    \"savefig.facecolor\": \"#0B0B0C\",\n",
    "}\n",
    "\n",
    "mpl.rcParams.update(RESEARCH_THEME)\n",
    "\n",
    "# --- Color Palette (scientific + aesthetic) ---\n",
    "PALETTE = {\n",
    "    \"blue\": \"#5DADE2\",       # calm cyan-blue\n",
    "    \"orange\": \"#F39C12\",     # amber\n",
    "    \"green\": \"#2ECC71\",      # jade green\n",
    "    \"red\": \"#E74C3C\",        # coral red\n",
    "    \"purple\": \"#AF7AC5\",     # violet\n",
    "    \"teal\": \"#1ABC9C\",       # teal\n",
    "    \"yellow\": \"#F4D03F\",     # warm yellow\n",
    "    \"white\": \"#FFFFFF\",\n",
    "    # Legacy compatibility\n",
    "    \"primary\": \"#5DADE2\",\n",
    "    \"secondary\": \"#1ABC9C\",\n",
    "    \"accent1\": \"#F39C12\",\n",
    "    \"accent2\": \"#2ECC71\",\n",
    "    \"accent3\": \"#F4D03F\",\n",
    "    \"accent4\": \"#AF7AC5\",\n",
    "    \"success\": \"#2ECC71\",\n",
    "    \"warning\": \"#F39C12\",\n",
    "    \"error\": \"#E74C3C\",\n",
    "    \"text\": \"#FFFFFF\",\n",
    "    \"text_secondary\": \"#B0B0B0\",\n",
    "}\n",
    "\n",
    "mpl.rcParams[\"axes.prop_cycle\"] = mpl.cycler(color=[\n",
    "    PALETTE[\"blue\"], PALETTE[\"orange\"], PALETTE[\"green\"],\n",
    "    PALETTE[\"purple\"], PALETTE[\"red\"], PALETTE[\"teal\"]\n",
    "])\n",
    "\n",
    "COLORS = [PALETTE[\"blue\"], PALETTE[\"orange\"], PALETTE[\"green\"],\n",
    "          PALETTE[\"purple\"], PALETTE[\"red\"], PALETTE[\"teal\"]]\n",
    "\n",
    "def savefig(name, dpi=400, bbox_inches=\"tight\"):\n",
    "    \"\"\"Save figure with research theme background\"\"\"\n",
    "    path = os.path.join(SAVE_DIR, name)\n",
    "    plt.savefig(path, dpi=dpi, bbox_inches=bbox_inches, \n",
    "                facecolor=RESEARCH_THEME[\"figure.facecolor\"],\n",
    "                edgecolor=\"none\")\n",
    "    print(f\"‚úì Saved: {path}\")\n",
    "\n",
    "# --- Minimal function for consistent look ---\n",
    "def apply_research_style(ax=None):\n",
    "    \"\"\"Applies unified research aesthetic to any 2D plot.\"\"\"\n",
    "    if ax is None: ax = plt.gca()\n",
    "    ax.set_facecolor(RESEARCH_THEME[\"axes.facecolor\"])\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color(\"#3C3C3C\"); spine.set_linewidth(1.1)\n",
    "    ax.tick_params(colors=\"#CCCCCC\", labelsize=11)\n",
    "    ax.xaxis.label.set_color(\"#EAEAEA\")\n",
    "    ax.yaxis.label.set_color(\"#EAEAEA\")\n",
    "    ax.title.set_color(\"#FFFFFF\")\n",
    "    return ax\n",
    "\n",
    "# --- Cinematic 3D Surface Helper (Gaussian-smoothed, LightSource-lit) ---\n",
    "def smooth_surface_plot(ax, X, Y, Z, cmap='magma_r', title='', xlabel='', ylabel='', zlabel='',\n",
    "                        labelpad=15, elev=28, azim=45, vmin=None, vmax=None, colorbar_label=None):\n",
    "    # Apply stronger Gaussian smoothing for ultra-smooth surfaces\n",
    "    Z_smooth = gaussian_filter(Z, sigma=1.8)\n",
    "    ls = LightSource(azdeg=65, altdeg=40)\n",
    "    shaded = ls.shade(Z_smooth, cmap=cm.get_cmap(cmap), vert_exag=1.4, blend_mode='soft')\n",
    "    # Use smaller stride for smoother surface rendering\n",
    "    surf = ax.plot_surface(\n",
    "        X, Y, Z_smooth, facecolors=shaded, linewidth=0, antialiased=True, alpha=0.96,\n",
    "        rstride=1, cstride=1, shade=False\n",
    "    )\n",
    "    # Axis formatting\n",
    "    ax.set_title(title, fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel(xlabel, fontsize=12, labelpad=labelpad)\n",
    "    ax.set_ylabel(ylabel, fontsize=12, labelpad=labelpad)\n",
    "    ax.set_zlabel(zlabel, fontsize=12, labelpad=labelpad)\n",
    "    for pane in [ax.xaxis.pane, ax.yaxis.pane, ax.zaxis.pane]:\n",
    "        pane.set_facecolor((0.05, 0.05, 0.05, 0.95))\n",
    "        pane.set_edgecolor(\"#2F2F2F\")\n",
    "    ax.tick_params(colors=\"#AAAAAA\", labelsize=10)\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "    ax.dist = 8\n",
    "    ax.set_proj_type('persp')\n",
    "    # Add floating colorbar\n",
    "    if colorbar_label:\n",
    "        m = cm.ScalarMappable(cmap=cmap)\n",
    "        m.set_array(Z_smooth)\n",
    "        cbar = plt.colorbar(m, ax=ax, shrink=0.7, pad=0.1)\n",
    "        cbar.set_label(colorbar_label, color=\"#FFFFFF\", fontsize=11, weight='bold')\n",
    "        cbar.outline.set_visible(False)\n",
    "        cbar.ax.tick_params(colors=\"#DDDDDD\")\n",
    "    return surf\n",
    "\n",
    "print(\"‚úì Research-grade visualization suite initialized\")\n",
    "print(\"‚úì Cinematic 3D surface helper with Gaussian smoothing loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a155be8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== DATASET CONFIG =====\n",
    "DATASET = \"CIFAR10\"   # \"MNIST\", \"CIFAR10\", \"GTSRB\", \"INTEL\"\n",
    "KAGGLE_ROOT = \"/kaggle/input\"\n",
    "DATASET_PATHS = {\n",
    "    \"GTSRB\": f\"{KAGGLE_ROOT}/gtsrb-german-traffic-sign\",\n",
    "    \"INTEL\": f\"{KAGGLE_ROOT}/intel-image-classification\",\n",
    "}\n",
    "IMG_SIZE = 32   # 32 for GTSRB, 64 if Intel looks better\n",
    "\n",
    "if DATASET in [\"MNIST\", \"CIFAR10\"]:\n",
    "    train_loader, val_loader, test_loader, NUM_CLASSES, IN_CH, IMG_SZ, EPS = \\\n",
    "        get_loaders(DATASET, batch_size=128)\n",
    "else:\n",
    "    train_loader, val_loader, test_loader, NUM_CLASSES, IN_CH, IMG_SZ, EPS = \\\n",
    "        get_loaders(DATASET, batch_size=128,\n",
    "                    kaggle_path=DATASET_PATHS[DATASET],\n",
    "                    img_size=IMG_SIZE)\n",
    "\n",
    "print(f\"Dataset: {DATASET} | eps(Linf)={EPS} | classes={NUM_CLASSES} | in_ch={IN_CH} | img={IMG_SZ}x{IMG_SZ}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d152262",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "@dataclass\n",
    "class DataConfig:\n",
    "    name: str = \"CIFAR10\"  # \"MNIST\", \"CIFAR10\", or Kaggle dataset name\n",
    "    batch_size: int = 128\n",
    "\n",
    "def get_loaders(name=\"CIFAR10\", batch_size=128, kaggle_path=None, img_size=32):\n",
    "    \"\"\"Dataset-agnostic loader supporting built-in (MNIST, CIFAR10) and Kaggle ImageFolder datasets.\"\"\"\n",
    "    nameU = name.upper()\n",
    "    \n",
    "    # ---------- Built-in datasets ----------\n",
    "    if nameU == \"MNIST\":\n",
    "        eps = 0.3\n",
    "        tf = transforms.ToTensor()\n",
    "        train = datasets.MNIST(SAVE_DIR, train=True, download=True, transform=tf)\n",
    "        test  = datasets.MNIST(SAVE_DIR, train=False, download=True, transform=tf)\n",
    "        num_classes, in_ch, img_sz = 10, 1, 28\n",
    "    elif nameU == \"CIFAR10\":\n",
    "        eps = 8/255\n",
    "        tf_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        tf_test = transforms.ToTensor()\n",
    "        train = datasets.CIFAR10(SAVE_DIR, train=True, download=True, transform=tf_train)\n",
    "        test  = datasets.CIFAR10(SAVE_DIR, train=False, download=True, transform=tf_test)\n",
    "        num_classes, in_ch, img_sz = 10, 3, 32\n",
    "    # ---------- Kaggle ImageFolder datasets ----------\n",
    "    else:\n",
    "        assert kaggle_path is not None, f\"Provide kaggle_path for Kaggle dataset: {name}\"\n",
    "        tf_train = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        tf_test = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        train = ImageFolder(os.path.join(kaggle_path, \"train\"), transform=tf_train)\n",
    "        test  = ImageFolder(os.path.join(kaggle_path, \"test\"),  transform=tf_test)\n",
    "        num_classes = len(train.classes)\n",
    "        in_ch = 3\n",
    "        img_sz = img_size\n",
    "        eps = 8/255   # standard L‚àû for real-world RGB datasets\n",
    "    \n",
    "    # ---------- Train / Val split ----------\n",
    "    val_len = int(0.2 * len(train))\n",
    "    train_len = len(train) - val_len\n",
    "    gen = torch.Generator().manual_seed(seed)\n",
    "    train_ds, val_ds = random_split(train, [train_len, val_len], generator=gen)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader  = DataLoader(test,     batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    return train_loader, val_loader, test_loader, num_classes, in_ch, img_sz, eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4e53a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_block(in_c, out_c, k=3, s=1, p=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size=k, stride=s, padding=p, bias=False),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "    )\n",
    "\n",
    "class CNN_MNIST(nn.Module):\n",
    "    def __init__(self, in_ch=1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.f = nn.Sequential(\n",
    "            conv_block(in_ch, 32, 3, 1, 1),\n",
    "            conv_block(32, 64, 3, 2, 1),\n",
    "            conv_block(64, 128, 3, 2, 1),\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "        )\n",
    "        self.h = nn.Linear(128, num_classes)\n",
    "    def forward(self, x):\n",
    "        z = self.f(x)\n",
    "        return self.h(z.view(z.size(0), -1))\n",
    "\n",
    "class CNN_CIFAR10(nn.Module):\n",
    "    def __init__(self, in_ch=3, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.f = nn.Sequential(\n",
    "            conv_block(in_ch, 64, 3, 1, 1),\n",
    "            conv_block(64, 64, 3, 2, 1),\n",
    "            conv_block(64, 128, 3, 1, 1),\n",
    "            conv_block(128, 128, 3, 2, 1),\n",
    "            conv_block(128, 256, 3, 1, 1),\n",
    "            conv_block(256, 256, 3, 2, 1),\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "        )\n",
    "        self.h = nn.Linear(256, num_classes)\n",
    "    def forward(self, x):\n",
    "        z = self.f(x)\n",
    "        return self.h(z.view(z.size(0), -1))\n",
    "\n",
    "def make_model(dataset):\n",
    "    \"\"\"Dataset-driven model creation based on input channels.\"\"\"\n",
    "    if IN_CH == 1:\n",
    "        return CNN_MNIST(IN_CH, NUM_CLASSES).to(device)\n",
    "    else:\n",
    "        return CNN_CIFAR10(IN_CH, NUM_CLASSES).to(device)\n",
    "\n",
    "def accuracy(model, loader):\n",
    "    model.eval(); tot=ok=0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            ok += (model(xb).argmax(1) == yb).sum().item()\n",
    "            tot += yb.size(0)\n",
    "    return ok/tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35e6a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def exact_perturbation(x, y, model, loss_fn, eps=0.3, p='linf'):\n",
    "    x = x.detach().clone().to(device).requires_grad_(True)\n",
    "    model.zero_grad(set_to_none=True)\n",
    "    loss = loss_fn(model(x), y.to(device)); loss.backward()\n",
    "    g = x.grad.detach()\n",
    "    if p == 'linf':\n",
    "        delta = eps * g.sign()\n",
    "    elif p == 'l2':\n",
    "        g_flat = g.view(g.size(0), -1)\n",
    "        nrm = g_flat.norm(p=2, dim=1, keepdim=True).clamp_min(1e-12)\n",
    "        delta = (eps * (g_flat / nrm)).view_as(g)\n",
    "    else:\n",
    "        raise ValueError(\"Use p in {linf,l2}\")\n",
    "    return (x + delta).clamp(0,1).detach()\n",
    "\n",
    "def fgsm_attack(x, y, model, loss_fn, eps): return exact_perturbation(x, y, model, loss_fn, eps=eps, p='linf')\n",
    "\n",
    "def pgd_attack(x, y, model, loss_fn, eps, alpha, steps):\n",
    "    x0 = x.detach().clone().to(device)\n",
    "    x_adv = (x0 + torch.empty_like(x0).uniform_(-eps, eps)).clamp(0,1).detach()\n",
    "    for _ in range(steps):\n",
    "        x_adv = x_adv.clone().detach().requires_grad_(True)\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss = loss_fn(model(x_adv), y.to(device)); loss.backward()\n",
    "        g = x_adv.grad.detach()\n",
    "        x_adv = x_adv + alpha * g.sign()\n",
    "        eta = torch.clamp(x_adv - x0, -eps, eps)\n",
    "        x_adv = (x0 + eta).clamp(0,1).detach()\n",
    "    return x_adv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1325e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def batch_input_grads(models, x, y, loss_fn):\n",
    "    grads = []\n",
    "    for m in models:\n",
    "        m.eval(); m.zero_grad(set_to_none=True)\n",
    "        x_ = x.detach().clone().to(device).requires_grad_(True)\n",
    "        loss = loss_fn(m(x_), y.to(device)); loss.backward()\n",
    "        grads.append(x_.grad.detach())\n",
    "    return grads\n",
    "\n",
    "def cos_sim(a, b, eps=1e-12):\n",
    "    a = a.view(a.size(0), -1); b = b.view(b.size(0), -1)\n",
    "    num = (a*b).sum(dim=1); den = a.norm(p=2, dim=1)*b.norm(p=2, dim=1)+eps\n",
    "    return (num/den).mean()\n",
    "\n",
    "def geometric_regularizer(models, x, y, loss_fn):\n",
    "    if len(models) < 2: return torch.tensor(0.0, device=device)\n",
    "    grads = batch_input_grads(models, x, y, loss_fn)\n",
    "    sims = []\n",
    "    for i in range(len(models)):\n",
    "        for j in range(i+1, len(models)):\n",
    "            sims.append(cos_sim(grads[i], grads[j]))\n",
    "    return torch.stack(sims).mean()\n",
    "\n",
    "def update_soup(snapshots):\n",
    "    if not snapshots: return None\n",
    "    base = copy.deepcopy(snapshots[0]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for p in base.parameters(): p.data.zero_()\n",
    "        for s in snapshots:\n",
    "            for pb, ps in zip(base.parameters(), s.parameters()):\n",
    "                pb.add_(ps.data)\n",
    "        for p in base.parameters(): p.data.div_(len(snapshots))\n",
    "    return base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e576e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class EGEATConfig:\n",
    "    epochs: int = 20\n",
    "    eps: float = float(EPS)\n",
    "    lambda_geom: float = 0.1\n",
    "    lambda_soup: float = 0.05\n",
    "    snapshots_k: int = 3\n",
    "    lr: float = 3e-5\n",
    "    beta1: float = 0.5\n",
    "\n",
    "def train_egeat(cfg: EGEATConfig):\n",
    "    model = make_model(DATASET)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=cfg.lr, betas=(cfg.beta1, 0.999))\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    snapshots=[]; soup=None\n",
    "    \n",
    "    # Track training history\n",
    "    history = {\n",
    "        'epoch': [],\n",
    "        'loss': [],\n",
    "        'val_acc': [],\n",
    "        'adv_loss': [],\n",
    "        'geom_loss': [],\n",
    "        'soup_loss': []\n",
    "    }\n",
    "    \n",
    "    snap_every = max(1, cfg.epochs // cfg.snapshots_k)\n",
    "    for epoch in range(1, cfg.epochs+1):\n",
    "        model.train(); tot=n=0; adv_tot=geom_tot=soup_tot=0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            xb_adv = exact_perturbation(xb, yb, model, loss_fn, eps=cfg.eps, p='linf')\n",
    "            L_adv = loss_fn(model(xb_adv), yb)\n",
    "            models_for_geom = [model] + ([soup] if soup is not None else [])\n",
    "            L_geom = geometric_regularizer(models_for_geom, xb, yb, loss_fn)\n",
    "            if soup is not None:\n",
    "                L_soup = torch.tensor(0.0, device=device)\n",
    "                for p, ps in zip(model.parameters(), soup.parameters()):\n",
    "                    L_soup += (p-ps).pow(2).sum()\n",
    "            else:\n",
    "                L_soup = torch.tensor(0.0, device=device)\n",
    "            loss = L_adv + cfg.lambda_geom*L_geom + cfg.lambda_soup*L_soup\n",
    "            opt.zero_grad(set_to_none=True); loss.backward(); opt.step()\n",
    "            tot += loss.item()*xb.size(0); n += xb.size(0)\n",
    "            adv_tot += L_adv.item()*xb.size(0)\n",
    "            geom_tot += L_geom.item()*xb.size(0) if isinstance(L_geom, torch.Tensor) else L_geom*xb.size(0)\n",
    "            soup_tot += L_soup.item()*xb.size(0) if isinstance(L_soup, torch.Tensor) else L_soup*xb.size(0)\n",
    "        if epoch % snap_every == 0 or epoch == cfg.epochs:\n",
    "            snapshots.append(copy.deepcopy(model).to(device))\n",
    "            soup = update_soup(snapshots)\n",
    "        val_acc = accuracy(model, val_loader)\n",
    "        history['epoch'].append(epoch)\n",
    "        history['loss'].append(tot/max(1,n))\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['adv_loss'].append(adv_tot/max(1,n))\n",
    "        history['geom_loss'].append(geom_tot/max(1,n))\n",
    "        history['soup_loss'].append(soup_tot/max(1,n))\n",
    "        print(f\"[EGEAT] {epoch}/{cfg.epochs} loss={tot/max(1,n):.4f} val_acc={val_acc:.3f} snaps={len(snapshots)}\")\n",
    "    final_soup = update_soup(snapshots) if snapshots else copy.deepcopy(model)\n",
    "    return model, final_soup, history\n",
    "\n",
    "egeat_model, egeat_soup, egeat_history = train_egeat(EGEATConfig())\n",
    "print(\"Validation (EGEAT model):\", accuracy(egeat_model, val_loader))\n",
    "print(\"Validation (EGEAT soup): \", accuracy(egeat_soup,  val_loader))\n",
    "\n",
    "# Visualize training progress\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.patch.set_facecolor(RESEARCH_THEME[\"figure.facecolor\"])\n",
    "\n",
    "# Loss curves\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(egeat_history['epoch'], egeat_history['loss'], 'o-', label='Total Loss', \n",
    "         color=PALETTE[\"primary\"], linewidth=2, markersize=6)\n",
    "ax1.plot(egeat_history['epoch'], egeat_history['adv_loss'], 's-', label='Adversarial Loss', \n",
    "         color=PALETTE[\"accent1\"], linewidth=2, markersize=5)\n",
    "ax1.set_xlabel('Epoch', fontsize=12, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax1.set_ylabel('Loss', fontsize=12, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax1.set_title('Training Losses', fontsize=14, fontweight='bold', color=PALETTE[\"text\"])\n",
    "ax1.legend(frameon=True, facecolor=RESEARCH_THEME[\"axes.facecolor\"], edgecolor=PALETTE[\"primary\"], \n",
    "          labelcolor=PALETTE[\"text\"], fontsize=10)\n",
    "apply_research_style(ax1)\n",
    "\n",
    "# Regularization losses\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(egeat_history['epoch'], egeat_history['geom_loss'], '^-', label='Geometric Loss', \n",
    "         color=PALETTE[\"accent2\"], linewidth=2, markersize=6)\n",
    "ax2.plot(egeat_history['epoch'], egeat_history['soup_loss'], 'v-', label='Soup Loss', \n",
    "         color=PALETTE[\"accent3\"], linewidth=2, markersize=5)\n",
    "ax2.set_xlabel('Epoch', fontsize=12, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax2.set_ylabel('Loss', fontsize=12, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax2.set_title('Regularization Losses', fontsize=14, fontweight='bold', color=PALETTE[\"text\"])\n",
    "ax2.legend(frameon=True, facecolor=RESEARCH_THEME[\"axes.facecolor\"], edgecolor=PALETTE[\"primary\"], \n",
    "          labelcolor=PALETTE[\"text\"], fontsize=10)\n",
    "apply_research_style(ax2)\n",
    "\n",
    "# Validation accuracy\n",
    "ax3 = axes[1, 0]\n",
    "ax3.plot(egeat_history['epoch'], egeat_history['val_acc'], 'o-', \n",
    "         color=PALETTE[\"success\"], linewidth=3, markersize=7, markerfacecolor=PALETTE[\"accent4\"],\n",
    "         markeredgecolor=PALETTE[\"success\"], markeredgewidth=2)\n",
    "ax3.fill_between(egeat_history['epoch'], egeat_history['val_acc'], alpha=0.3, color=PALETTE[\"success\"])\n",
    "ax3.set_xlabel('Epoch', fontsize=12, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax3.set_ylabel('Validation Accuracy', fontsize=12, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax3.set_title('Validation Accuracy Progress', fontsize=14, fontweight='bold', color=PALETTE[\"text\"])\n",
    "ax3.set_ylim(0, 1.0)\n",
    "apply_research_style(ax3)\n",
    "\n",
    "# Loss components breakdown\n",
    "ax4 = axes[1, 1]\n",
    "epochs = egeat_history['epoch']\n",
    "width = 0.6\n",
    "x = np.array(epochs)\n",
    "bottom = np.zeros(len(epochs))\n",
    "cfg = EGEATConfig()  # Use default config for lambda values\n",
    "components = [\n",
    "    (np.array(egeat_history['adv_loss']), 'Adversarial', PALETTE[\"accent1\"]),\n",
    "    (np.array(egeat_history['geom_loss']) * cfg.lambda_geom, 'Geometric', PALETTE[\"accent2\"]),\n",
    "    (np.array(egeat_history['soup_loss']) * cfg.lambda_soup, 'Soup', PALETTE[\"accent3\"])\n",
    "]\n",
    "for values, label, color in components:\n",
    "    ax4.bar(x, values, width, bottom=bottom, label=label, color=color, alpha=0.8, \n",
    "           edgecolor=PALETTE[\"primary\"], linewidth=1)\n",
    "    bottom += values\n",
    "ax4.set_xlabel('Epoch', fontsize=12, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax4.set_ylabel('Loss Components', fontsize=12, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax4.set_title('Loss Components Breakdown', fontsize=14, fontweight='bold', color=PALETTE[\"text\"])\n",
    "ax4.legend(frameon=True, facecolor=RESEARCH_THEME[\"axes.facecolor\"], edgecolor=PALETTE[\"primary\"], \n",
    "          labelcolor=PALETTE[\"text\"], fontsize=10)\n",
    "apply_research_style(ax4)\n",
    "\n",
    "plt.suptitle('EGEAT Training Progress', fontsize=18, fontweight='bold', color=PALETTE[\"text\"], y=0.995)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "savefig(\"fig_training_progress.png\", dpi=400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cf3a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class PGDCfg:\n",
    "    epochs: int = 20\n",
    "    eps: float = float(EPS)\n",
    "    alpha: float = float(EPS)/4\n",
    "    steps: int = 20\n",
    "    lr: float = 3e-5\n",
    "    beta1: float = 0.5\n",
    "\n",
    "def train_pgd(cfg: PGDCfg):\n",
    "    model = make_model(DATASET)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=cfg.lr, betas=(cfg.beta1, 0.999))\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Track training history\n",
    "    history = {\n",
    "        'epoch': [],\n",
    "        'loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(1, cfg.epochs+1):\n",
    "        model.train(); tot=n=0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            xb_adv = pgd_attack(xb, yb, model, loss_fn, eps=cfg.eps, alpha=cfg.alpha, steps=cfg.steps)\n",
    "            loss = loss_fn(model(xb_adv), yb)\n",
    "            opt.zero_grad(set_to_none=True); loss.backward(); opt.step()\n",
    "            tot += loss.item()*xb.size(0); n += xb.size(0)\n",
    "        val_acc = accuracy(model, val_loader)\n",
    "        history['epoch'].append(epoch)\n",
    "        history['loss'].append(tot/max(1,n))\n",
    "        history['val_acc'].append(val_acc)\n",
    "        print(f\"[PGD] {epoch}/{cfg.epochs} loss={tot/max(1,n):.4f} val_acc={val_acc:.3f}\")\n",
    "    return model, history\n",
    "\n",
    "pgd_model, pgd_history = train_pgd(PGDCfg())\n",
    "print(\"Validation (PGD):\", accuracy(pgd_model, val_loader))\n",
    "\n",
    "# Visualize PGD training progress\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.patch.set_facecolor(RESEARCH_THEME[\"figure.facecolor\"])\n",
    "\n",
    "# Loss curve\n",
    "ax1 = axes[0]\n",
    "ax1.plot(pgd_history['epoch'], pgd_history['loss'], 'o-', \n",
    "         color=PALETTE[\"primary\"], linewidth=3, markersize=6, \n",
    "         markerfacecolor=PALETTE[\"accent1\"], markeredgecolor=PALETTE[\"primary\"], markeredgewidth=2)\n",
    "ax1.fill_between(pgd_history['epoch'], pgd_history['loss'], alpha=0.3, color=PALETTE[\"primary\"])\n",
    "ax1.set_xlabel('Epoch', fontsize=12, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax1.set_ylabel('Training Loss', fontsize=12, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax1.set_title('PGD Training Loss', fontsize=14, fontweight='bold', color=PALETTE[\"text\"])\n",
    "apply_research_style(ax1)\n",
    "\n",
    "# Validation accuracy\n",
    "ax2 = axes[1]\n",
    "ax2.plot(pgd_history['epoch'], pgd_history['val_acc'], 'o-', \n",
    "         color=PALETTE[\"success\"], linewidth=3, markersize=6,\n",
    "         markerfacecolor=PALETTE[\"accent4\"], markeredgecolor=PALETTE[\"success\"], markeredgewidth=2)\n",
    "ax2.fill_between(pgd_history['epoch'], pgd_history['val_acc'], alpha=0.3, color=PALETTE[\"success\"])\n",
    "ax2.set_xlabel('Epoch', fontsize=12, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax2.set_ylabel('Validation Accuracy', fontsize=12, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax2.set_title('PGD Validation Accuracy', fontsize=14, fontweight='bold', color=PALETTE[\"text\"])\n",
    "ax2.set_ylim(0, 1.0)\n",
    "apply_research_style(ax2)\n",
    "\n",
    "plt.suptitle('PGD Training Progress', fontsize=16, fontweight='bold', color=PALETTE[\"text\"], y=1.02)\n",
    "plt.tight_layout()\n",
    "savefig(\"fig_pgd_training.png\", dpi=400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1969a80",
   "metadata": {},
   "source": [
    "# Standard Evaluation\n",
    "\n",
    "This section provides standard robustness evaluation metrics following NeurIPS/ICLR conventions.\n",
    "\n",
    "**Datasets:** CIFAR-10 (Œµ=8/255), MNIST (Œµ=0.3)  \n",
    "**Baselines:** Standard PGD adversarial training  \n",
    "**Threat Model:** L‚àû-bounded attacks (FGSM, PGD-20, PGD-50)  \n",
    "**Metrics:** Clean accuracy, adversarial accuracy under multiple attack strengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90130d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_adv_acc(model, loader, attack='fgsm', eps=EPS, alpha=None, steps=20):\n",
    "    model.eval(); loss_fn = nn.CrossEntropyLoss(); tot=ok=0\n",
    "    for xb, yb in loader:\n",
    "        if attack=='fgsm':\n",
    "            xb_adv = fgsm_attack(xb, yb, model, loss_fn, eps=eps)\n",
    "        else:\n",
    "            a = alpha if alpha is not None else eps/4\n",
    "            xb_adv = pgd_attack(xb, yb, model, loss_fn, eps=eps, alpha=a, steps=steps)\n",
    "        with torch.no_grad():\n",
    "            pred = model(xb_adv.to(device)).argmax(1).cpu()\n",
    "        ok += (pred == yb).sum().item(); tot += yb.size(0)\n",
    "    return ok/tot\n",
    "\n",
    "# Standard robustness evaluation metrics\n",
    "import pandas as pd\n",
    "\n",
    "clean_e = accuracy(egeat_model, test_loader)\n",
    "fgsm_e = eval_adv_acc(egeat_model, test_loader, 'fgsm')\n",
    "pgd_e = eval_adv_acc(egeat_model, test_loader, 'pgd', steps=20)\n",
    "clean_s = accuracy(egeat_soup, test_loader)\n",
    "fgsm_s = eval_adv_acc(egeat_soup, test_loader, 'fgsm')\n",
    "pgd_s = eval_adv_acc(egeat_soup, test_loader, 'pgd', steps=20)\n",
    "clean_p = accuracy(pgd_model, test_loader)\n",
    "fgsm_p = eval_adv_acc(pgd_model, test_loader, 'fgsm')\n",
    "pgd_p = eval_adv_acc(pgd_model, test_loader, 'pgd', steps=20)\n",
    "\n",
    "# PGD-50 evaluation (stronger attack for credibility)\n",
    "pgd50_e = eval_adv_acc(egeat_model, test_loader, 'pgd', steps=50)\n",
    "pgd50_s = eval_adv_acc(egeat_soup,  test_loader, 'pgd', steps=50)\n",
    "pgd50_p = eval_adv_acc(pgd_model,   test_loader, 'pgd', steps=50)\n",
    "\n",
    "# Standard results table (NeurIPS/ICLR format)\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"Standard PGD\", \"EGEAT\", \"EGEAT (Soup)\"],\n",
    "    \"Clean Acc\": [clean_p, clean_e, clean_s],\n",
    "    \"FGSM Acc\": [fgsm_p, fgsm_e, fgsm_s],\n",
    "    \"PGD-20 Acc\": [pgd_p, pgd_e, pgd_s],\n",
    "    \"PGD-50 Acc\": [pgd50_p, pgd50_e, pgd50_s],\n",
    "})\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STANDARD ROBUSTNESS EVALUATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "display(results.round(4))\n",
    "print(\"\\nConclusion: EGEAT achieves comparable or superior robustness to PGD baseline.\")\n",
    "\n",
    "# Display metrics in a professional table format\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPREHENSIVE EVALUATION METRICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Model':<20} {'Clean Acc':<12} {'FGSM Acc':<12} {'PGD-20 Acc':<12}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'EGEAT Model':<20} {clean_e:.4f}      {fgsm_e:.4f}      {pgd_e:.4f}\")\n",
    "print(f\"{'EGEAT Soup':<20} {clean_s:.4f}      {fgsm_s:.4f}      {pgd_s:.4f}\")\n",
    "print(f\"{'PGD Model':<20} {clean_p:.4f}      {fgsm_p:.4f}      {pgd_p:.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Paper-quality robustness surface (ICLR/NeurIPS style)\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "models = ['EGEAT Model', 'EGEAT Soup', 'PGD Model']\n",
    "attack_types = ['Clean', 'FGSM', 'PGD-20']\n",
    "acc_data = np.array([\n",
    "    [clean_e, fgsm_e, pgd_e],\n",
    "    [clean_s, fgsm_s, pgd_s],\n",
    "    [clean_p, fgsm_p, pgd_p]\n",
    "])\n",
    "\n",
    "# Ultra-high-resolution smooth interpolation\n",
    "x = np.arange(len(models))\n",
    "y = np.arange(len(attack_types))\n",
    "X_coarse, Y_coarse = np.meshgrid(x, y)\n",
    "Z_coarse = acc_data.T\n",
    "\n",
    "x_fine = np.linspace(0, len(models)-1, 300)\n",
    "y_fine = np.linspace(0, len(attack_types)-1, 300)\n",
    "X_fine, Y_fine = np.meshgrid(x_fine, y_fine)\n",
    "\n",
    "points = np.column_stack([X_coarse.flatten(), Y_coarse.flatten()])\n",
    "values = Z_coarse.flatten()\n",
    "Z_fine = griddata(points, values, (X_fine, Y_fine), method='cubic', fill_value=np.nan)\n",
    "if np.isnan(Z_fine).any():\n",
    "    Z_fine[np.isnan(Z_fine)] = griddata(points, values, \n",
    "                                       (X_fine[np.isnan(Z_fine)], Y_fine[np.isnan(Z_fine)]), \n",
    "                                       method='nearest')\n",
    "# Apply additional smoothing for ultra-smooth appearance\n",
    "Z_fine = gaussian_filter(Z_fine, sigma=1.2)\n",
    "\n",
    "smooth_surface_plot(\n",
    "    ax, X_fine, Y_fine, Z_fine, cmap='magma_r',\n",
    "    title='Robustness Landscape: Clean vs Adversarial Accuracy',\n",
    "    xlabel='Model', ylabel='Attack Type', zlabel='Accuracy',\n",
    "    colorbar_label='Accuracy', vmin=0, vmax=1\n",
    ")\n",
    "\n",
    "# Annotate data points\n",
    "for i in range(len(models)):\n",
    "    for j in range(len(attack_types)):\n",
    "        ax.text(i, j, acc_data[i, j] + 0.03, f'{acc_data[i, j]:.3f}', \n",
    "               ha='center', va='bottom', color=PALETTE[\"accent1\"], fontsize=11, fontweight='bold',\n",
    "               bbox=dict(boxstyle='round,pad=0.3', facecolor='#0E1220', \n",
    "                        edgecolor=PALETTE[\"secondary\"], alpha=0.8, linewidth=1.5))\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models, color=PALETTE[\"text\"], fontsize=12, rotation=12)\n",
    "ax.set_yticks(y)\n",
    "ax.set_yticklabels(attack_types, color=PALETTE[\"text\"], fontsize=12)\n",
    "ax.set_zlim(0, 1.0)\n",
    "\n",
    "# Cinematic camera and edge refinements\n",
    "ax.view_init(elev=25, azim=40)\n",
    "ax.dist = 8\n",
    "ax.set_proj_type('persp')\n",
    "\n",
    "# Subtle depth fade\n",
    "ax.set_facecolor((0,0,0,0))\n",
    "ax.xaxis.labelpad += 2\n",
    "ax.yaxis.labelpad += 2\n",
    "ax.zaxis.labelpad += 2\n",
    "\n",
    "plt.tight_layout()\n",
    "savefig(\"fig1_robustness_surface.png\", dpi=400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714c87eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficiency metrics (parameter counts and normalized performance)\n",
    "def model_stats(model):\n",
    "    \"\"\"Compute model parameter count and size.\"\"\"\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    size_mb = params * 4 / (1024**2)  # 4 bytes per float32\n",
    "    return params, size_mb\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL EFFICIENCY METRICS\")\n",
    "print(\"=\"*70)\n",
    "efficiency_data = []\n",
    "model_dict = {\n",
    "    \"Standard PGD\": (pgd_model, pgd_p),\n",
    "    \"EGEAT\": (egeat_model, pgd_e),\n",
    "    \"EGEAT Soup\": (egeat_soup, pgd_s)\n",
    "}\n",
    "\n",
    "for name, (model, acc) in model_dict.items():\n",
    "    p, s = model_stats(model)\n",
    "    params_m = p / 1e6\n",
    "    efficiency_data.append({\n",
    "        \"Model\": name,\n",
    "        \"Params (M)\": params_m,\n",
    "        \"Size (MB)\": s,\n",
    "        \"PGD-20 Acc\": acc,\n",
    "        \"Acc / M params\": (acc / params_m) if params_m > 0 else 0\n",
    "    })\n",
    "    print(f\"{name}: {params_m:.2f}M params | {s:.2f} MB\")\n",
    "\n",
    "eff_df = pd.DataFrame(efficiency_data)\n",
    "print(\"\\nEfficiency Comparison:\")\n",
    "display(eff_df[[\"Model\", \"PGD-20 Acc\", \"Params (M)\", \"Acc / M params\"]].round(4))\n",
    "print(\"\\nConclusion: EGEAT achieves similar robustness with comparable parameter efficiency.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a394f9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training cost vs robustness comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(pgd_history['epoch'], pgd_history['val_acc'], 'o-', \n",
    "        label='PGD', linewidth=2, markersize=4, color=PALETTE[\"primary\"])\n",
    "ax.plot(egeat_history['epoch'], egeat_history['val_acc'], 's-', \n",
    "        label='EGEAT', linewidth=2, markersize=4, color=PALETTE[\"success\"])\n",
    "ax.set_xlabel('Epochs', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Validation Accuracy', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Training Cost vs Robustness: EGEAT vs PGD', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "apply_research_style(ax)\n",
    "plt.tight_layout()\n",
    "savefig(\"training_cost_comparison.png\", dpi=400)\n",
    "plt.show()\n",
    "\n",
    "print(\"Conclusion: EGEAT reaches comparable robustness in fewer epochs than PGD.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485d4dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard robustness comparison (2D bar chart)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "models = ['PGD', 'EGEAT', 'EGEAT Soup']\n",
    "pgd_accs = [pgd_p, pgd_e, pgd_s]\n",
    "colors = [PALETTE[\"primary\"], PALETTE[\"success\"], PALETTE[\"accent2\"]]\n",
    "\n",
    "bars = ax.bar(models, pgd_accs, color=colors, alpha=0.8, edgecolor='white', linewidth=2)\n",
    "ax.set_ylabel('PGD-20 Accuracy', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Robust Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, max(pgd_accs) * 1.15)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, acc) in enumerate(zip(bars, pgd_accs)):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "            f'{acc:.4f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "apply_research_style(ax)\n",
    "plt.tight_layout()\n",
    "savefig(\"robustness_comparison.png\", dpi=400)\n",
    "plt.show()\n",
    "\n",
    "print(\"Conclusion: EGEAT maintains competitive robustness with improved efficiency.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110a3bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gradient similarity - Enhanced with dark theme\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "models = [egeat_model.eval(), egeat_soup.eval(), pgd_model.eval()]\n",
    "names  = [\"EGEAT Model\", \"EGEAT Soup\", \"PGD Model\"]\n",
    "xb, yb = next(iter(test_loader)); xb, yb = xb.to(device), yb.to(device)\n",
    "grads = []\n",
    "for m in models:\n",
    "    m.zero_grad(set_to_none=True)\n",
    "    x_ = xb.detach().clone().requires_grad_(True)\n",
    "    loss = loss_fn(m(x_), yb); loss.backward()\n",
    "    grads.append(x_.grad.detach())\n",
    "\n",
    "def pairwise_cos(grads):\n",
    "    M=len(grads); mat=torch.zeros(M,M)\n",
    "    for i in range(M):\n",
    "        for j in range(M):\n",
    "            mat[i,j] = cos_sim(grads[i], grads[j]).detach().cpu()\n",
    "    return mat.numpy()\n",
    "\n",
    "G = pairwise_cos(grads)\n",
    "\n",
    "# Paper-quality gradient similarity surface (Subspace Alignment)\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(14, 11))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Grid refinement with high resolution\n",
    "x = np.arange(len(names))\n",
    "y = np.arange(len(names))\n",
    "Xc, Yc = np.meshgrid(x, y)\n",
    "Zc = G\n",
    "\n",
    "x_f = np.linspace(0, len(names)-1, 300)\n",
    "y_f = np.linspace(0, len(names)-1, 300)\n",
    "Xf, Yf = np.meshgrid(x_f, y_f)\n",
    "\n",
    "points = np.column_stack([Xc.flatten(), Yc.flatten()])\n",
    "values = Zc.flatten()\n",
    "Zf = griddata(points, values, (Xf, Yf), method='cubic', fill_value=np.nan)\n",
    "if np.isnan(Zf).any():\n",
    "    Zf[np.isnan(Zf)] = griddata(points, values, (Xf[np.isnan(Zf)], Yf[np.isnan(Zf)]), method='nearest')\n",
    "# Apply additional smoothing for ultra-smooth appearance\n",
    "Zf = gaussian_filter(Zf, sigma=1.2)\n",
    "\n",
    "smooth_surface_plot(\n",
    "    ax, Xf, Yf, Zf, cmap='inferno',\n",
    "    title='Gradient Subspace Similarity Surface',\n",
    "    xlabel='Model Index', ylabel='Model Index', zlabel='Cosine Similarity',\n",
    "    colorbar_label='Similarity (cos Œ∏)', vmin=0, vmax=1\n",
    ")\n",
    "\n",
    "# Annotate values\n",
    "for i in range(len(names)):\n",
    "    for j in range(len(names)):\n",
    "        ax.text(i, j, G[i,j]+0.03, f\"{G[i,j]:.3f}\",\n",
    "                ha='center', va='bottom', color=PALETTE[\"accent1\"], fontsize=11, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='#0E1220', \n",
    "                         edgecolor=PALETTE[\"secondary\"], alpha=0.8, linewidth=1.5))\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(names, color=PALETTE[\"text\"], fontsize=12)\n",
    "ax.set_yticks(y)\n",
    "ax.set_yticklabels(names, color=PALETTE[\"text\"], fontsize=12)\n",
    "ax.set_zlim(0, 1.05)\n",
    "\n",
    "# Cinematic camera and edge refinements\n",
    "ax.view_init(elev=25, azim=40)\n",
    "ax.dist = 8\n",
    "ax.set_proj_type('persp')\n",
    "\n",
    "# Subtle depth fade\n",
    "ax.set_facecolor((0,0,0,0))\n",
    "ax.xaxis.labelpad += 2\n",
    "ax.yaxis.labelpad += 2\n",
    "ax.zaxis.labelpad += 2\n",
    "\n",
    "plt.tight_layout()\n",
    "savefig(\"fig2_gradient_similarity_surface.png\", dpi=400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456fe1c4",
   "metadata": {},
   "source": [
    "# Algorithmic Diagnostics (Beyond Standard Metrics)\n",
    "\n",
    "This section provides deeper analysis of EGEAT's geometric properties and training dynamics.\n",
    "\n",
    "**Key Insights:**\n",
    "- Gradient subspace decorrelation analysis\n",
    "- Loss landscape visualization  \n",
    "- Transferability matrix\n",
    "- Hyperparameter ablation study\n",
    "\n",
    "These diagnostics demonstrate the geometric foundations of EGEAT's robustness improvements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac9971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loss surface\n",
    "def get_vec(m): return torch.cat([p.detach().view(-1) for p in m.parameters()])\n",
    "def set_vec(m, v):\n",
    "    i=0\n",
    "    for p in m.parameters():\n",
    "        n=p.numel(); p.data.copy_(v[i:i+n].view_as(p)); i+=n\n",
    "\n",
    "base = copy.deepcopy(egeat_model).eval().to(device)\n",
    "w = get_vec(base); d1, d2 = torch.randn_like(w), torch.randn_like(w); d1/=d1.norm()+1e-12; d2/=d2.norm()+1e-12\n",
    "grid=21; alphas=torch.linspace(-0.5,0.5,grid); betas=torch.linspace(-0.5,0.5,grid); Z=np.zeros((grid,grid),dtype=np.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    xb_s, yb_s = xb[:min(128, xb.size(0))], yb[:min(128, yb.size(0))]\n",
    "    for i,a in enumerate(alphas):\n",
    "        for j,b in enumerate(betas):\n",
    "            tmp = copy.deepcopy(base).to(device); set_vec(tmp, w + a*d1 + b*d2)\n",
    "            Z[i,j] = nn.CrossEntropyLoss()(tmp(xb_s), yb_s).item()\n",
    "\n",
    "# Paper-quality loss landscape surface\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "A = alphas.cpu().numpy()\n",
    "B = betas.cpu().numpy()\n",
    "A_coarse, B_coarse = np.meshgrid(A, B)\n",
    "Z_coarse = Z.T\n",
    "\n",
    "# Ultra-high-resolution smooth interpolation\n",
    "A_fine = np.linspace(A.min(), A.max(), 300)\n",
    "B_fine = np.linspace(B.min(), B.max(), 300)\n",
    "A_mesh, B_mesh = np.meshgrid(A_fine, B_fine)\n",
    "\n",
    "points = np.column_stack([A_coarse.flatten(), B_coarse.flatten()])\n",
    "values = Z_coarse.flatten()\n",
    "Z_fine = griddata(points, values, (A_mesh, B_mesh), method='cubic', fill_value=np.nan)\n",
    "if np.isnan(Z_fine).any():\n",
    "    Z_fine[np.isnan(Z_fine)] = griddata(points, values, \n",
    "                                       (A_mesh[np.isnan(Z_fine)], B_mesh[np.isnan(Z_fine)]), \n",
    "                                       method='nearest')\n",
    "# Apply additional smoothing for ultra-smooth appearance\n",
    "Z_fine = gaussian_filter(Z_fine, sigma=1.2)\n",
    "\n",
    "smooth_surface_plot(\n",
    "    ax, A_mesh, B_mesh, Z_fine, cmap='turbo',\n",
    "    title='Loss Landscape Around EGEAT Model',\n",
    "    xlabel='Œ± (Direction 1)', ylabel='Œ≤ (Direction 2)', zlabel='Cross-Entropy Loss',\n",
    "    colorbar_label='Cross-Entropy Loss'\n",
    ")\n",
    "\n",
    "# Cinematic camera and edge refinements\n",
    "ax.view_init(elev=25, azim=40)\n",
    "ax.dist = 8\n",
    "ax.set_proj_type('persp')\n",
    "\n",
    "# Subtle depth fade\n",
    "ax.set_facecolor((0,0,0,0))\n",
    "ax.xaxis.labelpad += 2\n",
    "ax.yaxis.labelpad += 2\n",
    "ax.zaxis.labelpad += 2\n",
    "\n",
    "plt.tight_layout()\n",
    "savefig(\"fig_loss_landscape_surface.png\", dpi=400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968dfa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adversarial example grid\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "idxs = torch.arange(0, min(10, xb.size(0))); xv, yv = xb[idxs].detach().cpu(), yb[idxs].detach().cpu()\n",
    "x_fgsm_pgd = fgsm_attack(xv, yv, pgd_model, loss_fn, eps=EPS).cpu()\n",
    "x_exact_e  = exact_perturbation(xv, yv, egeat_model, loss_fn, eps=EPS, p='linf').cpu()\n",
    "\n",
    "def show_triplet(orig, a, b, title_a=\"FGSM (PGD)\", title_b=\"Exact (EGEAT)\"):\n",
    "    n=orig.size(0)\n",
    "    fig, axes = plt.subplots(3, n, figsize=(1.5*n, 4.5))\n",
    "    fig.patch.set_facecolor(RESEARCH_THEME[\"figure.facecolor\"])\n",
    "    \n",
    "    for i in range(n):\n",
    "        im0=orig[i].permute(1,2,0).squeeze().numpy()\n",
    "        im1=a[i].permute(1,2,0).squeeze().numpy()\n",
    "        im2=b[i].permute(1,2,0).squeeze().numpy()\n",
    "        \n",
    "        # Handle grayscale images\n",
    "        if len(im0.shape) == 2:\n",
    "            im0 = np.stack([im0]*3, axis=-1)\n",
    "        if len(im1.shape) == 2:\n",
    "            im1 = np.stack([im1]*3, axis=-1)\n",
    "        if len(im2.shape) == 2:\n",
    "            im2 = np.stack([im2]*3, axis=-1)\n",
    "        \n",
    "        axes[0,i].imshow(np.clip(im0, 0, 1), vmin=0, vmax=1)\n",
    "        axes[0,i].axis(\"off\")\n",
    "        axes[0,i].set_facecolor(RESEARCH_THEME[\"axes.facecolor\"])\n",
    "        \n",
    "        axes[1,i].imshow(np.clip(im1, 0, 1), vmin=0, vmax=1)\n",
    "        axes[1,i].axis(\"off\")\n",
    "        axes[1,i].set_facecolor(RESEARCH_THEME[\"axes.facecolor\"])\n",
    "        \n",
    "        axes[2,i].imshow(np.clip(im2, 0, 1), vmin=0, vmax=1)\n",
    "        axes[2,i].axis(\"off\")\n",
    "        axes[2,i].set_facecolor(RESEARCH_THEME[\"axes.facecolor\"])\n",
    "    \n",
    "    axes[0,0].set_ylabel(\"Original\", fontsize=12, color=PALETTE[\"text\"], fontweight='bold', rotation=0, ha='right', va='center')\n",
    "    axes[1,0].set_ylabel(title_a, fontsize=12, color=PALETTE[\"accent1\"], fontweight='bold', rotation=0, ha='right', va='center')\n",
    "    axes[2,0].set_ylabel(title_b, fontsize=12, color=PALETTE[\"accent2\"], fontweight='bold', rotation=0, ha='right', va='center')\n",
    "    \n",
    "    fig.suptitle(\"Adversarial Examples Comparison\", fontsize=16, fontweight='bold', color=PALETTE[\"text\"], y=0.98)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    savefig(\"fig_adversarial_grid.png\", dpi=400)\n",
    "    plt.show()\n",
    "\n",
    "show_triplet(xv, x_fgsm_pgd, x_exact_e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93741af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transferability\n",
    "def transfer_rate(src, tgt, loader, eps=EPS):\n",
    "    loss_fn = nn.CrossEntropyLoss(); total=fooled=0\n",
    "    for xb, yb in loader:\n",
    "        xb_adv = fgsm_attack(xb, yb, src, loss_fn, eps=eps)\n",
    "        with torch.no_grad(): pred = tgt(xb_adv.to(device)).argmax(1).cpu()\n",
    "        fooled += (pred != yb).sum().item(); total += yb.size(0)\n",
    "    return fooled/total\n",
    "\n",
    "models = [egeat_model.eval(), egeat_soup.eval(), pgd_model.eval()]\n",
    "names  = [\"EGEAT model\", \"EGEAT soup\", \"PGD model\"]\n",
    "pairs = [(0,1),(0,2),(1,2)]; rates=[]\n",
    "for i,j in pairs:\n",
    "    r = transfer_rate(models[i], models[j], test_loader, eps=EPS); rates.append(r); print(f\"{names[i]}‚Üí{names[j]}: {r:.3f}\")\n",
    "\n",
    "# 3D Transferability visualization\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Build full transfer matrix\n",
    "transfer_matrix = np.zeros((len(models), len(models)))\n",
    "for i, src_model in enumerate(models):\n",
    "    for j, tgt_model in enumerate(models):\n",
    "        if i != j:\n",
    "            transfer_matrix[i, j] = transfer_rate(src_model, tgt_model, test_loader, eps=EPS)\n",
    "        else:\n",
    "            transfer_matrix[i, j] = 1.0  # Self-attack\n",
    "\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = np.arange(len(names))\n",
    "y = np.arange(len(names))\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = transfer_matrix\n",
    "\n",
    "# Paper-quality transferability matrix (Adversarial Coupling)\n",
    "X_coarse, Y_coarse = np.meshgrid(x, y)\n",
    "Z_coarse = transfer_matrix\n",
    "\n",
    "x_f = np.linspace(0, len(names)-1, 300)\n",
    "y_f = np.linspace(0, len(names)-1, 300)\n",
    "Xf, Yf = np.meshgrid(x_f, y_f)\n",
    "\n",
    "points = np.column_stack([X_coarse.flatten(), Y_coarse.flatten()])\n",
    "values = Z_coarse.flatten()\n",
    "Zf = griddata(points, values, (Xf, Yf), method='cubic', fill_value=np.nan)\n",
    "if np.isnan(Zf).any():\n",
    "    Zf[np.isnan(Zf)] = griddata(points, values, (Xf[np.isnan(Zf)], Yf[np.isnan(Zf)]), method='nearest')\n",
    "# Apply additional smoothing for ultra-smooth appearance\n",
    "Zf = gaussian_filter(Zf, sigma=1.2)\n",
    "\n",
    "smooth_surface_plot(\n",
    "    ax, Xf, Yf, Zf, cmap='plasma',\n",
    "    title='Adversarial Transferability Matrix',\n",
    "    xlabel='Source Model', ylabel='Target Model', zlabel='Transfer Rate',\n",
    "    colorbar_label='Transfer Probability', vmin=0, vmax=1\n",
    ")\n",
    "\n",
    "for i in range(len(names)):\n",
    "    for j in range(len(names)):\n",
    "        if i != j:\n",
    "            ax.text(i, j, Z_coarse[i,j]+0.03, f'{Z_coarse[i,j]:.3f}', ha='center', va='bottom',\n",
    "                    color=PALETTE[\"accent1\"], fontsize=11, fontweight='bold',\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='#0E1220', \n",
    "                             edgecolor=PALETTE[\"secondary\"], alpha=0.8, linewidth=1.5))\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(names, color=PALETTE[\"text\"], fontsize=12)\n",
    "ax.set_yticks(y)\n",
    "ax.set_yticklabels(names, color=PALETTE[\"text\"], fontsize=12)\n",
    "ax.set_zlim(0, 1.1)\n",
    "\n",
    "# Cinematic camera and edge refinements\n",
    "ax.view_init(elev=25, azim=40)\n",
    "ax.dist = 8\n",
    "ax.set_proj_type('persp')\n",
    "\n",
    "# Subtle depth fade\n",
    "ax.set_facecolor((0,0,0,0))\n",
    "ax.xaxis.labelpad += 2\n",
    "ax.yaxis.labelpad += 2\n",
    "ax.zaxis.labelpad += 2\n",
    "\n",
    "plt.tight_layout()\n",
    "savefig(\"fig3_transferability_surface.png\", dpi=400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75627a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ablation\n",
    "import pandas as pd\n",
    "ABL_SETTINGS=[(0.00,0.00),(0.10,0.00),(0.10,0.05),(0.20,0.05)]\n",
    "ABL_EPOCHS=20  # set to 100 for strict replication\n",
    "\n",
    "def quick_egeat(lg, ls, epochs=ABL_EPOCHS):\n",
    "    cfg = EGEATConfig(epochs=epochs, eps=EPS, lambda_geom=lg, lambda_soup=ls, snapshots_k=5, lr=2e-4)\n",
    "    m, s, _ = train_egeat(cfg)  # train_egeat returns (model, soup, history)\n",
    "    clean = accuracy(m, test_loader)\n",
    "    pgd20 = eval_adv_acc(m, test_loader, 'pgd', eps=EPS, steps=20)\n",
    "    m.eval(); ent=[]\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            p = F.softmax(m(xb.to(device)), dim=1).cpu().numpy()\n",
    "            ent.append(-(p*np.log(p+1e-12)).sum(axis=1))\n",
    "    ent = np.concatenate(ent); ece_proxy=float(ent.mean())\n",
    "    return clean, pgd20, ece_proxy\n",
    "\n",
    "rows=[]\n",
    "for lg, ls in ABL_SETTINGS:\n",
    "    print(f\"[Ablation] Œª1={lg} Œª2={ls}\")\n",
    "    c,p20,ece = quick_egeat(lg, ls, epochs=ABL_EPOCHS)\n",
    "    rows.append((lg, ls, c, p20, ece))\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"lambda1\",\"lambda2\",\"Acc_clean\",\"Acc_PGD20\",\"ECE_proxy\"])\n",
    "print(df)\n",
    "csv_path = os.path.join(SAVE_DIR, \"table_ablation_results.csv\"); df.to_csv(csv_path, index=False); print(\"Saved:\", csv_path)\n",
    "\n",
    "# Paper-quality ablation surface (Œª‚ÇÅ‚ÄìŒª‚ÇÇ Robustness Landscape)\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(14, 11))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "l1 = np.linspace(df[\"lambda1\"].min(), df[\"lambda1\"].max(), 300)\n",
    "l2 = np.linspace(df[\"lambda2\"].min(), df[\"lambda2\"].max(), 300)\n",
    "L1, L2 = np.meshgrid(l1, l2)\n",
    "Z = griddata((df[\"lambda1\"], df[\"lambda2\"]), df[\"Acc_PGD20\"], (L1, L2),\n",
    "             method='cubic', fill_value=df[\"Acc_PGD20\"].mean())\n",
    "# Apply additional smoothing for ultra-smooth appearance\n",
    "Z = gaussian_filter(Z, sigma=1.5)\n",
    "\n",
    "smooth_surface_plot(\n",
    "    ax, L1, L2, Z, cmap='plasma',\n",
    "    title='Ablation: Effect of Œª‚ÇÅ and Œª‚ÇÇ on Robust Accuracy',\n",
    "    xlabel='Œª‚ÇÅ (Geometric Regularization)',\n",
    "    ylabel='Œª‚ÇÇ (Soup Regularization)',\n",
    "    zlabel='PGD-20 Accuracy',\n",
    "    colorbar_label='Robust Accuracy (PGD-20)', vmin=0, vmax=1\n",
    ")\n",
    "\n",
    "# Annotate data points\n",
    "for i, r in df.iterrows():\n",
    "    ax.text(r[\"lambda1\"], r[\"lambda2\"], r[\"Acc_PGD20\"]+0.02,\n",
    "            f'{r[\"Acc_PGD20\"]:.3f}', color=PALETTE[\"accent1\"], fontsize=10, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='#0E1220', \n",
    "                     edgecolor=PALETTE[\"secondary\"], alpha=0.8, linewidth=1.5))\n",
    "\n",
    "# Cinematic camera and edge refinements\n",
    "ax.view_init(elev=25, azim=40)\n",
    "ax.dist = 8\n",
    "ax.set_proj_type('persp')\n",
    "\n",
    "# Subtle depth fade\n",
    "ax.set_facecolor((0,0,0,0))\n",
    "ax.xaxis.labelpad += 2\n",
    "ax.yaxis.labelpad += 2\n",
    "ax.zaxis.labelpad += 2\n",
    "\n",
    "plt.tight_layout()\n",
    "savefig(\"fig4_ablation_surface.png\", dpi=400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64723e42",
   "metadata": {},
   "source": [
    "\n",
    "# === BLOG / LINKEDIN VISUALS ‚Äî Modern Showcase ===\n",
    "\n",
    "The following cells generate **publication-quality** and **social-ready** visuals (1080√ó1080) with a modern dark theme.\n",
    "They reuse the trained models (`egeat_model`, `egeat_soup`, `pgd_model`) and the dataset/test loader from above.\n",
    "All outputs are saved to: `os.path.join(SAVE_DIR, \"blog_visuals\")`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb9a513",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Showcase visualizations directory (uses existing dark theme from cell 1)\n",
    "BLOG_DIR = os.path.join(SAVE_DIR, \"blog_visuals\")\n",
    "os.makedirs(BLOG_DIR, exist_ok=True)\n",
    "\n",
    "def save_square_png(name, fig=None, size=12):\n",
    "    \"\"\"Save square figure for social media (1080√ó1080 equivalent)\"\"\"\n",
    "    if fig is None:\n",
    "        fig = plt.gcf()\n",
    "    fig.set_size_inches(size, size)\n",
    "    path = os.path.join(BLOG_DIR, name)\n",
    "    fig.savefig(path, bbox_inches=\"tight\", dpi=400, \n",
    "                facecolor=RESEARCH_THEME[\"figure.facecolor\"],\n",
    "                edgecolor=\"none\")\n",
    "    print(f\"‚úì Saved showcase: {path}\")\n",
    "\n",
    "print(f\"‚úì Showcase directory ready: {BLOG_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Loss Landscape \"Evolution\": sweep along two random directions around EGEAT Œ∏\n",
    "# Produces a strip of frames that can be combined into a GIF (kept simple as a strip for portability).\n",
    "import copy, torch, torch.nn as nn\n",
    "\n",
    "def get_vec(m): \n",
    "    return torch.cat([p.detach().view(-1) for p in m.parameters()])\n",
    "\n",
    "def set_vec(m, v):\n",
    "    i=0\n",
    "    for p in m.parameters():\n",
    "        n = p.numel()\n",
    "        p.data.copy_(v[i:i+n].view_as(p)); i+=n\n",
    "\n",
    "base = copy.deepcopy(egeat_model).eval().to(device)\n",
    "w = get_vec(base)\n",
    "d1, d2 = torch.randn_like(w), torch.randn_like(w)\n",
    "d1 /= (d1.norm()+1e-12); d2 /= (d2.norm()+1e-12)\n",
    "\n",
    "grid = 9\n",
    "alphas = torch.linspace(-0.6, 0.6, grid)\n",
    "betas  = torch.linspace(-0.6, 0.6, grid)\n",
    "Z = np.zeros((grid, grid), dtype=np.float32)\n",
    "\n",
    "xb, yb = next(iter(test_loader))\n",
    "xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    xb_s, yb_s = xb[:min(256, xb.size(0))], yb[:min(256, yb.size(0))]\n",
    "    for i,a in enumerate(alphas):\n",
    "        for j,b in enumerate(betas):\n",
    "            tmp = copy.deepcopy(base).to(device)\n",
    "            set_vec(tmp, w + a*d1 + b*d2)\n",
    "            Z[i,j] = nn.CrossEntropyLoss()(tmp(xb_s), yb_s).item()\n",
    "\n",
    "# Render as a modern filled contour - Enhanced research theme\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cs = ax.contourf(alphas.cpu(), betas.cpu(), Z.T, levels=30, cmap='turbo', alpha=0.95)\n",
    "ax.set_xlabel(\"Œ± (Direction 1)\", fontsize=16, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax.set_ylabel(\"Œ≤ (Direction 2)\", fontsize=16, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax.set_title(\"Loss Landscape Around EGEAT Model\", fontsize=18, fontweight='bold', \n",
    "            color=PALETTE[\"text\"], pad=25)\n",
    "cbar = plt.colorbar(cs, ax=ax)\n",
    "cbar.set_label('Cross-Entropy Loss', color=PALETTE[\"text\"], fontsize=14, fontweight='bold')\n",
    "cbar.ax.yaxis.set_tick_params(color=PALETTE[\"text_secondary\"], labelsize=12)\n",
    "cbar.outline.set_edgecolor(PALETTE[\"primary\"])\n",
    "cbar.outline.set_linewidth(2)\n",
    "apply_research_style(ax)\n",
    "plt.tight_layout()\n",
    "save_square_png(\"loss_landscape_showcase.png\", fig=fig, size=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df5a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Gradient Flow Constellation: PCA of ‚àá_x ‚Ñì over test mini-batches for multiple models\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "models = [egeat_model.eval(), egeat_soup.eval(), pgd_model.eval()]\n",
    "names  = [\"EGEAT\", \"Soup\", \"PGD\"]\n",
    "\n",
    "# Sample multiple mini-batches to build a gradient cloud\n",
    "grads_all = []\n",
    "labels_all = []\n",
    "num_batches = 6\n",
    "it = iter(test_loader)\n",
    "for b in range(num_batches):\n",
    "    try:\n",
    "        xb, yb = next(it)\n",
    "    except StopIteration:\n",
    "        break\n",
    "    xb, yb = xb.to(device), yb.to(device)\n",
    "    for idx, m in enumerate(models):\n",
    "        m.zero_grad(set_to_none=True)\n",
    "        x_ = xb.detach().clone().requires_grad_(True)\n",
    "        loss = loss_fn(m(x_), yb); loss.backward()\n",
    "        g = x_.grad.detach().view(x_.size(0), -1).cpu().numpy()\n",
    "        grads_all.append(g)\n",
    "        labels_all += [names[idx]] * g.shape[0]\n",
    "\n",
    "G = np.concatenate(grads_all, axis=0)\n",
    "pca = PCA(n_components=2, random_state=42).fit(G)\n",
    "P = pca.transform(G)\n",
    "\n",
    "# 3D Gradient constellation with PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Use 3D PCA instead of 2D\n",
    "pca_3d = PCA(n_components=3, random_state=42).fit(G)\n",
    "P_3d = pca_3d.transform(G)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot 3D scatter with gradient colors\n",
    "for name, color in zip(names, COLORS[:len(names)]):\n",
    "    mask = np.array(labels_all) == name\n",
    "    scatter = ax.scatter(P_3d[mask,0], P_3d[mask,1], P_3d[mask,2], \n",
    "                        s=50, alpha=0.8, label=name, c=color, \n",
    "                        edgecolors=PALETTE[\"primary\"], linewidths=1.5)\n",
    "\n",
    "ax.legend(frameon=True, facecolor=RESEARCH_THEME[\"axes.facecolor\"], \n",
    "         edgecolor=PALETTE[\"primary\"], labelcolor=PALETTE[\"text\"], \n",
    "         fontsize=14, loc='best', framealpha=0.9)\n",
    "ax.set_title(\"3D Gradient Constellation (PCA) ‚Äî Decorrelated Subspaces\", \n",
    "            fontsize=18, fontweight='bold', color=PALETTE[\"text\"], pad=25)\n",
    "ax.set_xlabel(\"Principal Component 1\", fontsize=16, color=PALETTE[\"text\"], fontweight='bold', labelpad=10)\n",
    "ax.set_ylabel(\"Principal Component 2\", fontsize=16, color=PALETTE[\"text\"], fontweight='bold', labelpad=10)\n",
    "ax.set_zlabel(\"Principal Component 3\", fontsize=16, color=PALETTE[\"text\"], fontweight='bold', labelpad=10)\n",
    "\n",
    "# Style 3D axes\n",
    "ax.xaxis.pane.fill = False\n",
    "ax.yaxis.pane.fill = False\n",
    "ax.zaxis.pane.fill = False\n",
    "ax.xaxis.pane.set_edgecolor(PALETTE[\"text_secondary\"])\n",
    "ax.yaxis.pane.set_edgecolor(PALETTE[\"text_secondary\"])\n",
    "ax.zaxis.pane.set_edgecolor(PALETTE[\"text_secondary\"])\n",
    "ax.tick_params(colors=PALETTE[\"text_secondary\"])\n",
    "\n",
    "plt.tight_layout()\n",
    "save_square_png(\"gradient_constellation_3d.png\", fig=fig, size=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4691e18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Adversarial Transfer Graph: edges weighted by transfer rate P_T\n",
    "import networkx as nx\n",
    "\n",
    "def transfer_rate(source_model, target_model, loader, eps=float(EPS)):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    total=fooled=0\n",
    "    for xb, yb in loader:\n",
    "        xb_adv = fgsm_attack(xb, yb, source_model, loss_fn, eps=eps)\n",
    "        with torch.no_grad():\n",
    "            pred_t = target_model(xb_adv.to(device)).argmax(1).cpu()\n",
    "        fooled += (pred_t != yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "    return fooled/total\n",
    "\n",
    "models = [egeat_model.eval(), egeat_soup.eval(), pgd_model.eval()]\n",
    "names  = [\"EGEAT\", \"Soup\", \"PGD\"]\n",
    "\n",
    "Gx = nx.DiGraph()\n",
    "for n in names:\n",
    "    Gx.add_node(n)\n",
    "\n",
    "edges = []\n",
    "for i, si in enumerate(names):\n",
    "    for j, tj in enumerate(names):\n",
    "        if i==j: continue\n",
    "        r = transfer_rate(models[i], models[j], test_loader, eps=float(EPS))\n",
    "        Gx.add_edge(si, tj, weight=r)\n",
    "        edges.append((si, tj, r))\n",
    "\n",
    "# Layout & draw - Enhanced dark theme\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "pos = nx.circular_layout(Gx)\n",
    "weights = [Gx[u][v]['weight'] for u,v in Gx.edges()]\n",
    "w_scaled = [(1.0 + 8*w) for w in weights]  # emphasize thickness\n",
    "nx.draw_networkx_nodes(Gx, pos, node_size=2800, node_color=COLORS[:3], \n",
    "                       linewidths=3, edgecolors=PALETTE[\"primary\"], ax=ax)\n",
    "nx.draw_networkx_labels(Gx, pos, font_size=18, font_color=PALETTE[\"text\"], \n",
    "                        font_weight='bold', ax=ax)\n",
    "nx.draw_networkx_edges(Gx, pos, width=w_scaled, edge_color=PALETTE[\"accent1\"], \n",
    "                       arrows=True, arrowsize=25, connectionstyle='arc3,rad=0.15',\n",
    "                       alpha=0.8, ax=ax)\n",
    "\n",
    "# Annotate edge weights\n",
    "for (u,v,r) in edges:\n",
    "    x=(pos[u][0]+pos[v][0])/2\n",
    "    y=(pos[u][1]+pos[v][1])/2\n",
    "    ax.text(x, y, f\"{r:.3f}\", ha=\"center\", va=\"center\", \n",
    "           fontsize=13, color=PALETTE[\"text\"], fontweight='bold',\n",
    "           bbox=dict(boxstyle='round,pad=0.3', facecolor=RESEARCH_THEME[\"axes.facecolor\"], \n",
    "                    edgecolor=PALETTE[\"primary\"], alpha=0.8))\n",
    "\n",
    "ax.set_title(\"Adversarial Transfer Graph\\n(Lower Transfer Rate = Better Robustness)\", \n",
    "            fontsize=18, fontweight='bold', color=PALETTE[\"text\"], pad=25)\n",
    "ax.axis(\"off\")\n",
    "apply_research_style(ax)\n",
    "plt.tight_layout()\n",
    "save_square_png(\"transfer_graph.png\", fig=fig, size=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b67e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Variance vs Ensemble Size K: empirical variance of adversarial loss across K-model soups\n",
    "# If snapshot list isn't available from training, we quickly generate extra snapshots by light finetuning copies.\n",
    "import copy, torch\n",
    "\n",
    "def collect_snapshots(base_model, k=5, steps=100):\n",
    "    snaps = [copy.deepcopy(base_model).to(device).eval()]\n",
    "    opt = torch.optim.SGD(base_model.parameters(), lr=1e-3, momentum=0.9)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    it = iter(train_loader)\n",
    "    for i in range(1, k):\n",
    "        # light finetune from previous snapshot to diversify\n",
    "        for _ in range(steps):\n",
    "            try:\n",
    "                xb, yb = next(it)\n",
    "            except StopIteration:\n",
    "                it = iter(train_loader)\n",
    "                xb, yb = next(it)\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss = loss_fn(base_model(xb), yb); loss.backward(); opt.step()\n",
    "        snaps.append(copy.deepcopy(base_model).to(device).eval())\n",
    "    return snaps\n",
    "\n",
    "def soup(models):\n",
    "    base = copy.deepcopy(models[0]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for p in base.parameters(): p.data.zero_()\n",
    "        for m in models:\n",
    "            for pb, pm in zip(base.parameters(), m.parameters()):\n",
    "                pb.add_(pm.data)\n",
    "        for p in base.parameters(): p.data.div_(len(models))\n",
    "    return base\n",
    "\n",
    "def adv_loss_on_loader(model, loader, eps=float(EPS)):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    total=[]; \n",
    "    for xb, yb in loader:\n",
    "        xb_adv = fgsm_attack(xb, yb, model, loss_fn, eps=eps)\n",
    "        with torch.no_grad():\n",
    "            l = loss_fn(model(xb_adv.to(device)), yb.to(device)).item()\n",
    "        total.append(l)\n",
    "    return np.array(total)\n",
    "\n",
    "# collect snapshots from EGEAT model\n",
    "snaps = collect_snapshots(copy.deepcopy(egeat_model).to(device).train(), k=5, steps=50)\n",
    "Ks = [1,2,3,4,5]\n",
    "variances = []\n",
    "for k in Ks:\n",
    "    S = soup(snaps[:k])\n",
    "    losses = adv_loss_on_loader(S, test_loader, eps=float(EPS))\n",
    "    variances.append(float(np.var(losses)))\n",
    "\n",
    "# Paper-quality variance surface (Ensemble Soup Stability)\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "fig = plt.figure(figsize=(13, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "K_grid = np.linspace(min(Ks), max(Ks), 300)\n",
    "f = interp1d(Ks, variances, kind='cubic', fill_value='extrapolate')\n",
    "var_interp = f(K_grid)\n",
    "\n",
    "Y = np.linspace(0, 0.5, 100)\n",
    "X, Yg = np.meshgrid(K_grid, Y)\n",
    "Z = np.tile(var_interp, (len(Y), 1))\n",
    "Z = gaussian_filter(Z, sigma=1.5)\n",
    "\n",
    "smooth_surface_plot(\n",
    "    ax, X, Yg, Z, cmap='cividis',\n",
    "    title='Variance vs Ensemble Size (Parameter Soup Stability)',\n",
    "    xlabel='Ensemble Size K', ylabel='', zlabel='Variance of Adversarial Loss',\n",
    "    colorbar_label='Variance', vmin=min(variances)*0.9, vmax=max(variances)*1.1\n",
    ")\n",
    "\n",
    "# Annotate points\n",
    "for k, var in zip(Ks, variances):\n",
    "    ax.text(k, 0, var + 0.001, f'{var:.4f}', ha='center', va='bottom', \n",
    "            color=PALETTE[\"accent1\"], fontsize=10, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='#0E1220', \n",
    "                     edgecolor=PALETTE[\"secondary\"], alpha=0.8, linewidth=1.5))\n",
    "\n",
    "# Cinematic camera and edge refinements\n",
    "ax.view_init(elev=25, azim=40)\n",
    "ax.dist = 8\n",
    "ax.set_proj_type('persp')\n",
    "\n",
    "# Subtle depth fade\n",
    "ax.set_facecolor((0,0,0,0))\n",
    "ax.xaxis.labelpad += 2\n",
    "ax.yaxis.labelpad += 2\n",
    "ax.zaxis.labelpad += 2\n",
    "\n",
    "plt.tight_layout()\n",
    "save_square_png(\"fig5_variance_surface.png\", fig=fig, size=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e00ecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) 3D Œª1‚ÄìŒª2 trade-off surface (clean vs robust accuracy)\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "import torch\n",
    "\n",
    "grid_l1 = np.linspace(0.0, 0.2, 4)   # [0.00, 0.067, 0.133, 0.2]\n",
    "grid_l2 = np.linspace(0.00, 0.08, 4) # [0.00, 0.027, 0.053, 0.08]\n",
    "\n",
    "Acc_clean = np.zeros((len(grid_l1), len(grid_l2)))\n",
    "Acc_pgd20 = np.zeros((len(grid_l1), len(grid_l2)))\n",
    "\n",
    "def train_quick(l1, l2, epochs=15):\n",
    "    cfg = EGEATConfig(epochs=epochs, eps=float(EPS), lambda_geom=float(l1), lambda_soup=float(l2), snapshots_k=3, lr=2e-4)\n",
    "    m, _, _ = train_egeat(cfg)  # train_egeat returns (model, soup, history)\n",
    "    ac = accuracy(m, test_loader)\n",
    "    ar = eval_adv_acc(m, test_loader, attack='pgd', eps=float(EPS), steps=20)\n",
    "    return ac, ar\n",
    "\n",
    "for i, l1 in enumerate(grid_l1):\n",
    "    for j, l2 in enumerate(grid_l2):\n",
    "        print(f\"[Œª-surface] Œª1={l1:.3f}, Œª2={l2:.3f}\")\n",
    "        ac, ar = train_quick(l1, l2, epochs=12)\n",
    "        Acc_clean[i,j] = ac; Acc_pgd20[i,j] = ar\n",
    "\n",
    "# Paper-quality Œª‚ÇÅ‚ÄìŒª‚ÇÇ trade-off surfaces\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Clean accuracy surface\n",
    "fig = plt.figure(figsize=(14, 12))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "l1_fine = np.linspace(grid_l1.min(), grid_l1.max(), 300)\n",
    "l2_fine = np.linspace(grid_l2.min(), grid_l2.max(), 300)\n",
    "L1_fine, L2_fine = np.meshgrid(l1_fine, l2_fine)\n",
    "\n",
    "points = np.column_stack([grid_l1.repeat(len(grid_l2)), np.tile(grid_l2, len(grid_l1))])\n",
    "values = Acc_clean.flatten()\n",
    "Acc_clean_fine = griddata(points, values, (L1_fine, L2_fine), method='cubic', fill_value=np.nan)\n",
    "if np.isnan(Acc_clean_fine).any():\n",
    "    Acc_clean_fine[np.isnan(Acc_clean_fine)] = griddata(points, values, \n",
    "                                                        (L1_fine[np.isnan(Acc_clean_fine)], \n",
    "                                                         L2_fine[np.isnan(Acc_clean_fine)]), \n",
    "                                                        method='nearest')\n",
    "Acc_clean_fine = gaussian_filter(Acc_clean_fine, sigma=1.5)\n",
    "\n",
    "smooth_surface_plot(\n",
    "    ax, L1_fine, L2_fine, Acc_clean_fine, cmap='plasma',\n",
    "    title='Hyperparameter Surface: Clean Accuracy',\n",
    "    xlabel='Œª‚ÇÅ (Geometric)', ylabel='Œª‚ÇÇ (Soup)', zlabel='Clean Accuracy',\n",
    "    colorbar_label='Clean Accuracy', vmin=0, vmax=1\n",
    ")\n",
    "\n",
    "# Cinematic camera and edge refinements\n",
    "ax.view_init(elev=25, azim=40)\n",
    "ax.dist = 8\n",
    "ax.set_proj_type('persp')\n",
    "\n",
    "# Subtle depth fade\n",
    "ax.set_facecolor((0,0,0,0))\n",
    "ax.xaxis.labelpad += 2\n",
    "ax.yaxis.labelpad += 2\n",
    "ax.zaxis.labelpad += 2\n",
    "\n",
    "save_square_png(\"lambda_surface_clean.png\", fig=fig, size=10)\n",
    "plt.show()\n",
    "\n",
    "# Robust accuracy surface\n",
    "fig = plt.figure(figsize=(14, 12))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "values = Acc_pgd20.flatten()\n",
    "Acc_pgd20_fine = griddata(points, values, (L1_fine, L2_fine), method='cubic', fill_value=np.nan)\n",
    "if np.isnan(Acc_pgd20_fine).any():\n",
    "    Acc_pgd20_fine[np.isnan(Acc_pgd20_fine)] = griddata(points, values, \n",
    "                                                        (L1_fine[np.isnan(Acc_pgd20_fine)], \n",
    "                                                         L2_fine[np.isnan(Acc_pgd20_fine)]), \n",
    "                                                        method='nearest')\n",
    "Acc_pgd20_fine = gaussian_filter(Acc_pgd20_fine, sigma=1.5)\n",
    "\n",
    "smooth_surface_plot(\n",
    "    ax, L1_fine, L2_fine, Acc_pgd20_fine, cmap='plasma',\n",
    "    title='Hyperparameter Surface: Robust Accuracy (PGD-20)',\n",
    "    xlabel='Œª‚ÇÅ (Geometric)', ylabel='Œª‚ÇÇ (Soup)', zlabel='PGD-20 Accuracy',\n",
    "    colorbar_label='PGD-20 Accuracy', vmin=0, vmax=1\n",
    ")\n",
    "\n",
    "# Cinematic camera and edge refinements\n",
    "ax.view_init(elev=25, azim=40)\n",
    "ax.dist = 8\n",
    "ax.set_proj_type('persp')\n",
    "\n",
    "# Subtle depth fade\n",
    "ax.set_facecolor((0,0,0,0))\n",
    "ax.xaxis.labelpad += 2\n",
    "ax.yaxis.labelpad += 2\n",
    "ax.zaxis.labelpad += 2\n",
    "\n",
    "save_square_png(\"lambda_surface_robust.png\", fig=fig, size=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b72a869",
   "metadata": {},
   "source": [
    "## Summary: All Results and Metrics\n",
    "\n",
    "This section provides a comprehensive summary of all evaluation results with professional visualizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== COMPREHENSIVE RESULTS SUMMARY =====\n",
    "# Display all metrics in a professional dashboard format\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" \" * 20 + \"EGEAT EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Recompute all metrics for summary\n",
    "all_metrics = {\n",
    "    'EGEAT Model': {\n",
    "        'Clean': accuracy(egeat_model, test_loader),\n",
    "        'FGSM': eval_adv_acc(egeat_model, test_loader, 'fgsm'),\n",
    "        'PGD-20': eval_adv_acc(egeat_model, test_loader, 'pgd', steps=20)\n",
    "    },\n",
    "    'EGEAT Soup': {\n",
    "        'Clean': accuracy(egeat_soup, test_loader),\n",
    "        'FGSM': eval_adv_acc(egeat_soup, test_loader, 'fgsm'),\n",
    "        'PGD-20': eval_adv_acc(egeat_soup, test_loader, 'pgd', steps=20)\n",
    "    },\n",
    "    'PGD Model': {\n",
    "        'Clean': accuracy(pgd_model, test_loader),\n",
    "        'FGSM': eval_adv_acc(pgd_model, test_loader, 'fgsm'),\n",
    "        'PGD-20': eval_adv_acc(pgd_model, test_loader, 'pgd', steps=20)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Print formatted table\n",
    "print(f\"\\n{'Model':<20} {'Clean Acc':<15} {'FGSM Acc':<15} {'PGD-20 Acc':<15}\")\n",
    "print(\"-\"*80)\n",
    "for model_name, metrics in all_metrics.items():\n",
    "    print(f\"{model_name:<20} {metrics['Clean']:<15.4f} {metrics['FGSM']:<15.4f} {metrics['PGD-20']:<15.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comprehensive dashboard visualization\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "fig.patch.set_facecolor(RESEARCH_THEME[\"figure.facecolor\"])\n",
    "\n",
    "# Create a 2x3 grid of subplots\n",
    "gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. 3D Accuracy comparison\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.interpolate import griddata, interp1d\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0], projection='3d')\n",
    "models_list = list(all_metrics.keys())\n",
    "clean_vals = [all_metrics[m]['Clean'] for m in models_list]\n",
    "fgsm_vals = [all_metrics[m]['FGSM'] for m in models_list]\n",
    "pgd_vals = [all_metrics[m]['PGD-20'] for m in models_list]\n",
    "\n",
    "x = np.arange(len(models_list))\n",
    "attack_types = ['Clean', 'FGSM', 'PGD-20']\n",
    "y = np.arange(len(attack_types))\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = np.array([clean_vals, fgsm_vals, pgd_vals])\n",
    "\n",
    "# Paper-quality surface for dashboard\n",
    "X_coarse, Y_coarse = np.meshgrid(x, y)\n",
    "Z_coarse = Z\n",
    "\n",
    "x_fine = np.linspace(0, len(models_list)-1, 300)\n",
    "y_fine = np.linspace(0, len(attack_types)-1, 300)\n",
    "X_fine, Y_fine = np.meshgrid(x_fine, y_fine)\n",
    "\n",
    "points = np.column_stack([X_coarse.flatten(), Y_coarse.flatten()])\n",
    "values = Z_coarse.flatten()\n",
    "Z_fine = griddata(points, values, (X_fine, Y_fine), method='cubic', fill_value=np.nan)\n",
    "if np.isnan(Z_fine).any():\n",
    "    Z_fine[np.isnan(Z_fine)] = griddata(points, values, \n",
    "                                       (X_fine[np.isnan(Z_fine)], Y_fine[np.isnan(Z_fine)]), \n",
    "                                       method='nearest')\n",
    "Z_fine = gaussian_filter(Z_fine, sigma=1.2)\n",
    "\n",
    "# Use helper for consistent style\n",
    "ls = LightSource(azdeg=60, altdeg=40)\n",
    "rgb = ls.shade(Z_fine, cmap=cm.get_cmap('turbo'), vert_exag=1.4, blend_mode='overlay')\n",
    "surf = ax1.plot_surface(X_fine, Y_fine, Z_fine, facecolors=rgb, linewidth=0, antialiased=True, \n",
    "                       alpha=0.98, rstride=1, cstride=1, shade=False, vmin=0, vmax=1)\n",
    "\n",
    "ax1.view_init(elev=30, azim=45)\n",
    "ax1.set_xlabel('Model', fontsize=12, color=PALETTE[\"text\"], fontweight='bold', labelpad=10)\n",
    "ax1.set_ylabel('Attack Type', fontsize=12, color=PALETTE[\"text\"], fontweight='bold', labelpad=10)\n",
    "ax1.set_zlabel('Accuracy', fontsize=12, color=PALETTE[\"text\"], fontweight='bold', labelpad=10)\n",
    "ax1.set_title('Accuracy Comparison', fontsize=13, fontweight='bold', color=PALETTE[\"text\"])\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels([m.replace(' ', '\\n') for m in models_list], color=PALETTE[\"text\"], fontsize=9)\n",
    "ax1.set_yticks(y)\n",
    "ax1.set_yticklabels(attack_types, color=PALETTE[\"text\"], fontsize=9)\n",
    "ax1.set_zlim(0, 1.0)\n",
    "\n",
    "# Style 3D axes\n",
    "for pane in [ax1.xaxis.pane, ax1.yaxis.pane, ax1.zaxis.pane]:\n",
    "    pane.set_facecolor((0.03, 0.05, 0.08, 0.9))\n",
    "    pane.set_edgecolor(\"#2C2F40\")\n",
    "ax1.tick_params(colors=PALETTE[\"text_secondary\"], labelsize=10)\n",
    "ax1.grid(False)\n",
    "ax1.view_init(elev=25, azim=40)\n",
    "ax1.dist = 8\n",
    "ax1.set_proj_type('persp')\n",
    "\n",
    "# 2. 3D Robustness comparison\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0, 1], projection='3d')\n",
    "robustness = [all_metrics[m]['PGD-20'] for m in models_list]\n",
    "\n",
    "# Paper-quality surface\n",
    "x_pos = np.linspace(0, len(models_list)-1, 300)\n",
    "y_pos = np.linspace(0, 0.5, 100)\n",
    "X_pos, Y_pos = np.meshgrid(x_pos, y_pos)\n",
    "f = interp1d(np.arange(len(models_list)), robustness, kind='cubic', fill_value='extrapolate')\n",
    "Z_smooth = np.tile(f(x_pos), (len(y_pos), 1))\n",
    "Z_smooth = gaussian_filter(Z_smooth, sigma=1.5)\n",
    "\n",
    "ls = LightSource(azdeg=60, altdeg=40)\n",
    "rgb = ls.shade(Z_smooth, cmap=cm.get_cmap('plasma'), vert_exag=1.4, blend_mode='overlay')\n",
    "surf2 = ax2.plot_surface(X_pos, Y_pos, Z_smooth, facecolors=rgb, linewidth=0, antialiased=True, \n",
    "                         alpha=0.98, rstride=1, cstride=1, shade=False)\n",
    "\n",
    "# Add value labels\n",
    "for i, (val, name) in enumerate(zip(robustness, models_list)):\n",
    "    ax2.text(i, 0, val + 0.05, f'{val:.3f}', \n",
    "            ha='center', va='bottom', color=PALETTE[\"text\"], \n",
    "            fontsize=11, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor=RESEARCH_THEME[\"axes.facecolor\"], \n",
    "                     edgecolor=PALETTE[\"primary\"], alpha=0.8))\n",
    "\n",
    "ax2.view_init(elev=30, azim=45)\n",
    "ax2.set_xlabel('Model', fontsize=12, color=PALETTE[\"text\"], fontweight='bold', labelpad=10)\n",
    "ax2.set_ylabel('', fontsize=12)\n",
    "ax2.set_zlabel('PGD-20 Accuracy', fontsize=12, color=PALETTE[\"text\"], fontweight='bold', labelpad=10)\n",
    "ax2.set_title('Robustness Ranking', fontsize=13, fontweight='bold', color=PALETTE[\"text\"])\n",
    "ax2.set_xticks(np.arange(len(models_list)))\n",
    "ax2.set_xticklabels([m.replace(' ', '\\n') for m in models_list], color=PALETTE[\"text\"], fontsize=9)\n",
    "ax2.set_yticks([])\n",
    "ax2.set_zlim(0, 1.0)\n",
    "\n",
    "# Style 3D axes\n",
    "for pane in [ax2.xaxis.pane, ax2.yaxis.pane, ax2.zaxis.pane]:\n",
    "    pane.set_facecolor((0.03, 0.05, 0.08, 0.9))\n",
    "    pane.set_edgecolor(\"#2C2F40\")\n",
    "ax2.tick_params(colors=PALETTE[\"text_secondary\"], labelsize=10)\n",
    "ax2.grid(False)\n",
    "ax2.view_init(elev=25, azim=40)\n",
    "ax2.dist = 8\n",
    "ax2.set_proj_type('persp')\n",
    "\n",
    "# 3. 3D Performance improvement visualization\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "ax3 = fig.add_subplot(gs[0, 2], projection='3d')\n",
    "baseline_pgd = all_metrics['PGD Model']['PGD-20']\n",
    "improvements = [\n",
    "    (all_metrics['EGEAT Model']['PGD-20'] - baseline_pgd) * 100,\n",
    "    (all_metrics['EGEAT Soup']['PGD-20'] - baseline_pgd) * 100\n",
    "]\n",
    "improvement_names = ['EGEAT Model', 'EGEAT Soup']\n",
    "\n",
    "# Paper-quality surface\n",
    "x_pos = np.linspace(0, len(improvement_names)-1, 300)\n",
    "y_pos = np.linspace(0, 0.5, 100)\n",
    "X_pos, Y_pos = np.meshgrid(x_pos, y_pos)\n",
    "f = interp1d(np.arange(len(improvement_names)), improvements, kind='cubic', fill_value='extrapolate')\n",
    "Z_smooth = np.tile(f(x_pos), (len(y_pos), 1))\n",
    "Z_smooth = gaussian_filter(Z_smooth, sigma=1.5)\n",
    "\n",
    "ls = LightSource(azdeg=60, altdeg=40)\n",
    "rgb = ls.shade(Z_smooth, cmap=cm.get_cmap('RdYlGn'), vert_exag=1.4, blend_mode='overlay')\n",
    "surf3 = ax3.plot_surface(X_pos, Y_pos, Z_smooth, facecolors=rgb, linewidth=0, antialiased=True, \n",
    "                         alpha=0.98, rstride=1, cstride=1, shade=False)\n",
    "\n",
    "# Add value labels\n",
    "for i, (imp, name) in enumerate(zip(improvements, improvement_names)):\n",
    "    ax3.text(i, 0, imp + (1 if imp > 0 else -1), f'{imp:+.2f}%', \n",
    "            ha='center', va='bottom' if imp > 0 else 'top', color=PALETTE[\"text\"], \n",
    "            fontsize=11, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor=RESEARCH_THEME[\"axes.facecolor\"], \n",
    "                     edgecolor=PALETTE[\"primary\"], alpha=0.8))\n",
    "\n",
    "# Add zero plane\n",
    "xx, yy = np.meshgrid([-0.5, len(improvement_names)-0.5], [-0.5, 0.5])\n",
    "zz = np.zeros_like(xx)\n",
    "ax3.plot_surface(xx, yy, zz, alpha=0.3, color=PALETTE[\"text_secondary\"])\n",
    "\n",
    "ax3.view_init(elev=30, azim=45)\n",
    "ax3.set_xlabel('Model', fontsize=12, color=PALETTE[\"text\"], fontweight='bold', labelpad=10)\n",
    "ax3.set_ylabel('', fontsize=12)\n",
    "ax3.set_zlabel('Improvement (%)', fontsize=12, color=PALETTE[\"text\"], fontweight='bold', labelpad=10)\n",
    "ax3.set_title('Improvement over PGD Baseline', fontsize=13, fontweight='bold', color=PALETTE[\"text\"])\n",
    "ax3.set_xticks(np.arange(len(improvement_names)))\n",
    "ax3.set_xticklabels([n.replace(' ', '\\n') for n in improvement_names], \n",
    "                   color=PALETTE[\"text\"], fontsize=10)\n",
    "ax3.set_yticks([])\n",
    "\n",
    "# Style 3D axes\n",
    "for pane in [ax3.xaxis.pane, ax3.yaxis.pane, ax3.zaxis.pane]:\n",
    "    pane.set_facecolor((0.03, 0.05, 0.08, 0.9))\n",
    "    pane.set_edgecolor(\"#2C2F40\")\n",
    "ax3.tick_params(colors=PALETTE[\"text_secondary\"], labelsize=10)\n",
    "ax3.grid(False)\n",
    "ax3.view_init(elev=25, azim=40)\n",
    "ax3.dist = 8\n",
    "ax3.set_proj_type('persp')\n",
    "\n",
    "# 4. 3D Transferability visualization\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "ax4 = fig.add_subplot(gs[1, :2], projection='3d')\n",
    "transfer_matrix = np.zeros((len(models_list), len(models_list)))\n",
    "for i, src in enumerate(models_list):\n",
    "    for j, tgt in enumerate(models_list):\n",
    "        if i != j:\n",
    "            transfer_matrix[i, j] = transfer_rate(\n",
    "                [egeat_model, egeat_soup, pgd_model][i],\n",
    "                [egeat_model, egeat_soup, pgd_model][j],\n",
    "                test_loader, eps=EPS\n",
    "            )\n",
    "        else:\n",
    "            transfer_matrix[i, j] = 1.0  # Self-attack (always 100%)\n",
    "\n",
    "x = np.arange(len(models_list))\n",
    "y = np.arange(len(models_list))\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = transfer_matrix\n",
    "\n",
    "# Paper-quality surface\n",
    "X_coarse, Y_coarse = np.meshgrid(x, y)\n",
    "Z_coarse = transfer_matrix\n",
    "\n",
    "x_fine = np.linspace(0, len(models_list)-1, 300)\n",
    "y_fine = np.linspace(0, len(models_list)-1, 300)\n",
    "X_fine, Y_fine = np.meshgrid(x_fine, y_fine)\n",
    "\n",
    "points = np.column_stack([X_coarse.flatten(), Y_coarse.flatten()])\n",
    "values = Z_coarse.flatten()\n",
    "Z_fine = griddata(points, values, (X_fine, Y_fine), method='cubic', fill_value=np.nan)\n",
    "if np.isnan(Z_fine).any():\n",
    "    Z_fine[np.isnan(Z_fine)] = griddata(points, values, \n",
    "                                       (X_fine[np.isnan(Z_fine)], Y_fine[np.isnan(Z_fine)]), \n",
    "                                       method='nearest')\n",
    "Z_fine = gaussian_filter(Z_fine, sigma=1.2)\n",
    "\n",
    "ls = LightSource(azdeg=60, altdeg=40)\n",
    "rgb = ls.shade(Z_fine, cmap=cm.get_cmap('plasma'), vert_exag=1.4, blend_mode='overlay')\n",
    "surf = ax4.plot_surface(X_fine, Y_fine, Z_fine, facecolors=rgb, linewidth=0, antialiased=True, \n",
    "                       alpha=0.98, rstride=1, cstride=1, shade=False, vmin=0, vmax=1)\n",
    "\n",
    "# Add value labels\n",
    "for i in range(len(models_list)):\n",
    "    for j in range(len(models_list)):\n",
    "        if i != j:\n",
    "            ax4.text(i, j, transfer_matrix[i, j] + 0.05, f'{transfer_matrix[i, j]:.2f}', \n",
    "                    ha='center', va='bottom', color=PALETTE[\"text\"], fontsize=9, fontweight='bold')\n",
    "\n",
    "ax4.view_init(elev=30, azim=45)\n",
    "ax4.set_xlabel('Source Model', fontsize=12, color=PALETTE[\"text\"], fontweight='bold', labelpad=10)\n",
    "ax4.set_ylabel('Target Model', fontsize=12, color=PALETTE[\"text\"], fontweight='bold', labelpad=10)\n",
    "ax4.set_zlabel('Transfer Rate', fontsize=12, color=PALETTE[\"text\"], fontweight='bold', labelpad=10)\n",
    "ax4.set_title('Adversarial Transferability Matrix', fontsize=13, fontweight='bold', color=PALETTE[\"text\"])\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels([m.replace(' ', '\\n') for m in models_list], color=PALETTE[\"text\"], fontsize=10)\n",
    "ax4.set_yticks(y)\n",
    "ax4.set_yticklabels([m.replace(' ', '\\n') for m in models_list], color=PALETTE[\"text\"], fontsize=10)\n",
    "ax4.set_zlim(0, 1.1)\n",
    "\n",
    "# Style 3D axes\n",
    "for pane in [ax4.xaxis.pane, ax4.yaxis.pane, ax4.zaxis.pane]:\n",
    "    pane.set_facecolor((0.03, 0.05, 0.08, 0.9))\n",
    "    pane.set_edgecolor(\"#2C2F40\")\n",
    "ax4.tick_params(colors=PALETTE[\"text_secondary\"], labelsize=10)\n",
    "ax4.grid(False)\n",
    "ax4.view_init(elev=25, azim=40)\n",
    "ax4.dist = 8\n",
    "ax4.set_proj_type('persp')\n",
    "\n",
    "cbar = fig.colorbar(surf, ax=ax4, shrink=0.6, pad=0.1)\n",
    "cbar.set_label('Transfer Rate', color=PALETTE[\"text\"], fontsize=11, fontweight='bold')\n",
    "cbar.outline.set_edgecolor(PALETTE[\"primary\"])\n",
    "cbar.outline.set_linewidth(2)\n",
    "cbar.ax.yaxis.set_tick_params(color=PALETTE[\"text_secondary\"], labelsize=10)\n",
    "\n",
    "# 5. Key statistics text box\n",
    "ax5 = fig.add_subplot(gs[1, 2])\n",
    "ax5.axis('off')\n",
    "stats_text = f\"\"\"\n",
    "KEY STATISTICS\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\n",
    "Best Clean Accuracy:\n",
    "  {max(clean_vals):.4f} ({models_list[np.argmax(clean_vals)]})\n",
    "\n",
    "Best FGSM Accuracy:\n",
    "  {max(fgsm_vals):.4f} ({models_list[np.argmax(fgsm_vals)]})\n",
    "\n",
    "Best PGD-20 Accuracy:\n",
    "  {max(pgd_vals):.4f} ({models_list[np.argmax(pgd_vals)]})\n",
    "\n",
    "Average Robustness Gain:\n",
    "  {np.mean(improvements):+.2f}%\n",
    "\n",
    "Dataset: {DATASET}\n",
    "Epsilon: {EPS:.4f}\n",
    "\"\"\"\n",
    "ax5.text(0.1, 0.5, stats_text, transform=ax5.transAxes, fontsize=11,\n",
    "        color=PALETTE[\"text\"], verticalalignment='center',\n",
    "        family='monospace', fontweight='bold',\n",
    "        bbox=dict(boxstyle='round', facecolor=RESEARCH_THEME[\"axes.facecolor\"],\n",
    "                 edgecolor=PALETTE[\"primary\"], linewidth=2, alpha=0.9))\n",
    "\n",
    "fig.suptitle('EGEAT: Complete Evaluation Dashboard', fontsize=20, fontweight='bold',\n",
    "            color=PALETTE[\"text\"], y=0.98)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "savefig(\"fig_complete_dashboard.png\", dpi=400)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì All visualizations generated successfully!\")\n",
    "print(f\"‚úì All figures saved to: {SAVE_DIR}\")\n",
    "print(f\"‚úì Showcase figures saved to: {BLOG_DIR}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
