{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62f01271",
   "metadata": {},
   "source": [
    "\n",
    "# EGEAT — Exact Geometric Ensemble Adversarial Training\n",
    "\n",
    "**Implements Algorithm 1 exactly** with Eq. (11) (exact inner maximization), Eq. (4) (geometric regularizer), and Eq. (5) (weight‑space smoothing).  \n",
    "Datasets: **MNIST (ε=0.3)** and **CIFAR‑10 (ε=8/255)**. DCGAN‑inspired CNNs.  \n",
    "Training defaults (Sec. V‑C): **K=5, λ₁=0.1, λ₂=0.05, batch=128, Adam(2e‑4, β₁=0.5), epochs=100**.  \n",
    "Evaluations: Clean, FGSM, PGD‑20; gradient similarity; loss surface; transferability; ablation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab20331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, math, random, time, copy, itertools\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SAVE_DIR = \"/content\" if os.path.exists(\"/content\") else \".\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "print(\"Device:\", device, \"| SAVE_DIR:\", SAVE_DIR)\n",
    "\n",
    "# ===== DARK LINKEDIN-STYLE THEME =====\n",
    "# High-contrast dark theme for professional presentations\n",
    "DARK_THEME = {\n",
    "    \"figure.facecolor\": \"#0A0E27\",      # Deep dark blue-black background\n",
    "    \"axes.facecolor\": \"#0F1629\",        # Slightly lighter for axes\n",
    "    \"axes.edgecolor\": \"#4A90E2\",        # LinkedIn blue for edges\n",
    "    \"axes.labelcolor\": \"#E8F0FE\",       # Light blue-white for labels\n",
    "    \"xtick.color\": \"#B8C5D6\",          # Soft gray-blue for ticks\n",
    "    \"ytick.color\": \"#B8C5D6\",\n",
    "    \"text.color\": \"#E8F0FE\",            # Light text\n",
    "    \"font.size\": 14,\n",
    "    \"font.weight\": \"medium\",\n",
    "    \"axes.linewidth\": 1.5,\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.color\": \"#1A2332\",\n",
    "    \"grid.alpha\": 0.3,\n",
    "    \"grid.linewidth\": 0.8,\n",
    "    \"figure.dpi\": 150,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"savefig.facecolor\": \"#0A0E27\",\n",
    "    \"savefig.edgecolor\": \"none\",\n",
    "}\n",
    "\n",
    "mpl.rcParams.update(DARK_THEME)\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \"#0F1629\"})\n",
    "\n",
    "# Professional color palette (high contrast, colorblind-friendly)\n",
    "PALETTE = {\n",
    "    \"primary\": \"#0077B5\",      # LinkedIn blue\n",
    "    \"secondary\": \"#00A0DC\",    # Light LinkedIn blue\n",
    "    \"accent1\": \"#FF6B35\",       # Coral orange\n",
    "    \"accent2\": \"#4ECDC4\",       # Turquoise\n",
    "    \"accent3\": \"#FFE66D\",       # Yellow\n",
    "    \"accent4\": \"#A8E6CF\",       # Mint green\n",
    "    \"success\": \"#28A745\",       # Green\n",
    "    \"warning\": \"#FFC107\",       # Amber\n",
    "    \"error\": \"#DC3545\",         # Red\n",
    "    \"text\": \"#E8F0FE\",          # Light text\n",
    "    \"text_secondary\": \"#B8C5D6\", # Secondary text\n",
    "}\n",
    "\n",
    "COLORS = [PALETTE[\"primary\"], PALETTE[\"accent1\"], PALETTE[\"accent2\"], \n",
    "          PALETTE[\"accent3\"], PALETTE[\"accent4\"], PALETTE[\"secondary\"]]\n",
    "\n",
    "def savefig(name, dpi=300, bbox_inches=\"tight\"):\n",
    "    \"\"\"Save figure with dark theme background\"\"\"\n",
    "    path = os.path.join(SAVE_DIR, name)\n",
    "    plt.savefig(path, dpi=dpi, bbox_inches=bbox_inches, \n",
    "                facecolor=DARK_THEME[\"figure.facecolor\"],\n",
    "                edgecolor=\"none\")\n",
    "    print(f\"✓ Saved: {path}\")\n",
    "\n",
    "def apply_dark_style(ax=None):\n",
    "    \"\"\"Apply dark theme to current axes\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    ax.set_facecolor(DARK_THEME[\"axes.facecolor\"])\n",
    "    ax.spines['bottom'].set_color(PALETTE[\"primary\"])\n",
    "    ax.spines['top'].set_color(PALETTE[\"primary\"])\n",
    "    ax.spines['right'].set_color(PALETTE[\"primary\"])\n",
    "    ax.spines['left'].set_color(PALETTE[\"primary\"])\n",
    "    ax.tick_params(colors=PALETTE[\"text_secondary\"])\n",
    "    ax.xaxis.label.set_color(PALETTE[\"text\"])\n",
    "    ax.yaxis.label.set_color(PALETTE[\"text\"])\n",
    "    ax.title.set_color(PALETTE[\"text\"])\n",
    "    return ax\n",
    "\n",
    "print(\"✓ Dark LinkedIn-style theme initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d152262",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class DataConfig:\n",
    "    name: str = \"CIFAR10\"  # \"MNIST\" or \"CIFAR10\"\n",
    "    batch_size: int = 128\n",
    "\n",
    "def get_loaders(name=\"CIFAR10\", batch_size=128):\n",
    "    if name.upper() == \"MNIST\":\n",
    "        eps = 0.3\n",
    "        tf = transforms.ToTensor()\n",
    "        train = datasets.MNIST(root=SAVE_DIR, train=True, download=True, transform=tf)\n",
    "        test  = datasets.MNIST(root=SAVE_DIR, train=False, download=True, transform=tf)\n",
    "        num_classes = 10; in_ch = 1; img_sz = 28\n",
    "    elif name.upper() == \"CIFAR10\":\n",
    "        eps = 8/255\n",
    "        tf_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        tf_test = transforms.ToTensor()\n",
    "        train = datasets.CIFAR10(root=SAVE_DIR, train=True, download=True, transform=tf_train)\n",
    "        test  = datasets.CIFAR10(root=SAVE_DIR, train=False, download=True, transform=tf_test)\n",
    "        num_classes = 10; in_ch = 3; img_sz = 32\n",
    "    else:\n",
    "        raise ValueError(\"Unknown dataset\")\n",
    "\n",
    "    val_len = int(0.2 * len(train))\n",
    "    train_len = len(train) - val_len\n",
    "    gen = torch.Generator().manual_seed(seed)\n",
    "    train_ds, val_ds = random_split(train, [train_len, val_len], generator=gen)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader  = DataLoader(test,     batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    return train_loader, val_loader, test_loader, num_classes, in_ch, img_sz, eps\n",
    "\n",
    "DATASET = \"CIFAR10\"\n",
    "train_loader, val_loader, test_loader, NUM_CLASSES, IN_CH, IMG_SZ, EPS = get_loaders(DATASET, 128)\n",
    "print(f\"Dataset: {DATASET} | eps(Linf)={EPS} | classes={NUM_CLASSES} | in_ch={IN_CH} | img={IMG_SZ}x{IMG_SZ}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4e53a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_block(in_c, out_c, k=3, s=1, p=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size=k, stride=s, padding=p, bias=False),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "    )\n",
    "\n",
    "class CNN_MNIST(nn.Module):\n",
    "    def __init__(self, in_ch=1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.f = nn.Sequential(\n",
    "            conv_block(in_ch, 32, 3, 1, 1),\n",
    "            conv_block(32, 64, 3, 2, 1),\n",
    "            conv_block(64, 128, 3, 2, 1),\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "        )\n",
    "        self.h = nn.Linear(128, num_classes)\n",
    "    def forward(self, x):\n",
    "        z = self.f(x)\n",
    "        return self.h(z.view(z.size(0), -1))\n",
    "\n",
    "class CNN_CIFAR10(nn.Module):\n",
    "    def __init__(self, in_ch=3, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.f = nn.Sequential(\n",
    "            conv_block(in_ch, 64, 3, 1, 1),\n",
    "            conv_block(64, 64, 3, 2, 1),\n",
    "            conv_block(64, 128, 3, 1, 1),\n",
    "            conv_block(128, 128, 3, 2, 1),\n",
    "            conv_block(128, 256, 3, 1, 1),\n",
    "            conv_block(256, 256, 3, 2, 1),\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "        )\n",
    "        self.h = nn.Linear(256, num_classes)\n",
    "    def forward(self, x):\n",
    "        z = self.f(x)\n",
    "        return self.h(z.view(z.size(0), -1))\n",
    "\n",
    "def make_model(dataset):\n",
    "    return (CNN_MNIST if dataset.upper()==\"MNIST\" else CNN_CIFAR10)(IN_CH, NUM_CLASSES).to(device)\n",
    "\n",
    "def accuracy(model, loader):\n",
    "    model.eval(); tot=ok=0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            ok += (model(xb).argmax(1) == yb).sum().item()\n",
    "            tot += yb.size(0)\n",
    "    return ok/tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35e6a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def exact_perturbation(x, y, model, loss_fn, eps=0.3, p='linf'):\n",
    "    x = x.detach().clone().to(device).requires_grad_(True)\n",
    "    model.zero_grad(set_to_none=True)\n",
    "    loss = loss_fn(model(x), y.to(device)); loss.backward()\n",
    "    g = x.grad.detach()\n",
    "    if p == 'linf':\n",
    "        delta = eps * g.sign()\n",
    "    elif p == 'l2':\n",
    "        g_flat = g.view(g.size(0), -1)\n",
    "        nrm = g_flat.norm(p=2, dim=1, keepdim=True).clamp_min(1e-12)\n",
    "        delta = (eps * (g_flat / nrm)).view_as(g)\n",
    "    else:\n",
    "        raise ValueError(\"Use p in {linf,l2}\")\n",
    "    return (x + delta).clamp(0,1).detach()\n",
    "\n",
    "def fgsm_attack(x, y, model, loss_fn, eps): return exact_perturbation(x, y, model, loss_fn, eps=eps, p='linf')\n",
    "\n",
    "def pgd_attack(x, y, model, loss_fn, eps, alpha, steps):\n",
    "    x0 = x.detach().clone().to(device)\n",
    "    x_adv = (x0 + torch.empty_like(x0).uniform_(-eps, eps)).clamp(0,1).detach()\n",
    "    for _ in range(steps):\n",
    "        x_adv = x_adv.clone().detach().requires_grad_(True)\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        loss = loss_fn(model(x_adv), y.to(device)); loss.backward()\n",
    "        g = x_adv.grad.detach()\n",
    "        x_adv = x_adv + alpha * g.sign()\n",
    "        eta = torch.clamp(x_adv - x0, -eps, eps)\n",
    "        x_adv = (x0 + eta).clamp(0,1).detach()\n",
    "    return x_adv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1325e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def batch_input_grads(models, x, y, loss_fn):\n",
    "    grads = []\n",
    "    for m in models:\n",
    "        m.eval(); m.zero_grad(set_to_none=True)\n",
    "        x_ = x.detach().clone().to(device).requires_grad_(True)\n",
    "        loss = loss_fn(m(x_), y.to(device)); loss.backward()\n",
    "        grads.append(x_.grad.detach())\n",
    "    return grads\n",
    "\n",
    "def cos_sim(a, b, eps=1e-12):\n",
    "    a = a.view(a.size(0), -1); b = b.view(b.size(0), -1)\n",
    "    num = (a*b).sum(dim=1); den = a.norm(p=2, dim=1)*b.norm(p=2, dim=1)+eps\n",
    "    return (num/den).mean()\n",
    "\n",
    "def geometric_regularizer(models, x, y, loss_fn):\n",
    "    if len(models) < 2: return torch.tensor(0.0, device=device)\n",
    "    grads = batch_input_grads(models, x, y, loss_fn)\n",
    "    sims = []\n",
    "    for i in range(len(models)):\n",
    "        for j in range(i+1, len(models)):\n",
    "            sims.append(cos_sim(grads[i], grads[j]))\n",
    "    return torch.stack(sims).mean()\n",
    "\n",
    "def update_soup(snapshots):\n",
    "    if not snapshots: return None\n",
    "    base = copy.deepcopy(snapshots[0]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for p in base.parameters(): p.data.zero_()\n",
    "        for s in snapshots:\n",
    "            for pb, ps in zip(base.parameters(), s.parameters()):\n",
    "                pb.add_(ps.data)\n",
    "        for p in base.parameters(): p.data.div_(len(snapshots))\n",
    "    return base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e576e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class EGEATConfig:\n",
    "    epochs: int = 20          \n",
    "    eps: float = float(EPS)\n",
    "    lambda_geom: float = 0.1\n",
    "    lambda_soup: float = 0.05\n",
    "    snapshots_k: int = 3      \n",
    "    lr: float = 3e-4          \n",
    "    beta1: float = 0.5\n",
    "\n",
    "def train_egeat(cfg: EGEATConfig):\n",
    "    model = make_model(DATASET)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=cfg.lr, betas=(cfg.beta1, 0.999))\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    snapshots=[]; soup=None\n",
    "    snap_every = max(1, cfg.epochs // cfg.snapshots_k)\n",
    "    for epoch in range(1, cfg.epochs+1):\n",
    "        model.train(); tot=n=0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            xb_adv = exact_perturbation(xb, yb, model, loss_fn, eps=cfg.eps, p='linf')\n",
    "            L_adv = loss_fn(model(xb_adv), yb)\n",
    "            models_for_geom = [model] + ([soup] if soup is not None else [])\n",
    "            L_geom = geometric_regularizer(models_for_geom, xb, yb, loss_fn)\n",
    "            if soup is not None:\n",
    "                L_soup = torch.tensor(0.0, device=device)\n",
    "                for p, ps in zip(model.parameters(), soup.parameters()):\n",
    "                    L_soup += (p-ps).pow(2).sum()\n",
    "            else:\n",
    "                L_soup = torch.tensor(0.0, device=device)\n",
    "            loss = L_adv + cfg.lambda_geom*L_geom + cfg.lambda_soup*L_soup\n",
    "            opt.zero_grad(set_to_none=True); loss.backward(); opt.step()\n",
    "            tot += loss.item()*xb.size(0); n += xb.size(0)\n",
    "        if epoch % snap_every == 0 or epoch == cfg.epochs:\n",
    "            snapshots.append(copy.deepcopy(model).to(device))\n",
    "            soup = update_soup(snapshots)\n",
    "        print(f\"[EGEAT] {epoch}/{cfg.epochs} loss={tot/max(1,n):.4f} val_acc={accuracy(model,val_loader):.3f} snaps={len(snapshots)}\")\n",
    "    final_soup = update_soup(snapshots) if snapshots else copy.deepcopy(model)\n",
    "    return model, final_soup\n",
    "\n",
    "egeat_model, egeat_soup = train_egeat(EGEATConfig())\n",
    "print(\"Validation (EGEAT model):\", accuracy(egeat_model, val_loader))\n",
    "print(\"Validation (EGEAT soup): \", accuracy(egeat_soup,  val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cf3a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class PGDCfg:\n",
    "    epochs: int = 20                \n",
    "    eps: float = float(EPS)\n",
    "    alpha: float = float(EPS) / 4\n",
    "    steps: int = 7                  \n",
    "    lr: float = 3e-4                \n",
    "    beta1: float = 0.5\n",
    "\n",
    "def train_pgd(cfg: PGDCfg):\n",
    "    model = make_model(DATASET)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=cfg.lr, betas=(cfg.beta1, 0.999))\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    for epoch in range(1, cfg.epochs+1):\n",
    "        model.train(); tot=n=0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            xb_adv = pgd_attack(xb, yb, model, loss_fn, eps=cfg.eps, alpha=cfg.alpha, steps=cfg.steps)\n",
    "            loss = loss_fn(model(xb_adv), yb)\n",
    "            opt.zero_grad(set_to_none=True); loss.backward(); opt.step()\n",
    "            tot += loss.item()*xb.size(0); n += xb.size(0)\n",
    "        print(f\"[PGD] {epoch}/{cfg.epochs} loss={tot/max(1,n):.4f} val_acc={accuracy(model,val_loader):.3f}\")\n",
    "    return model\n",
    "\n",
    "pgd_model = train_pgd(PGDCfg())\n",
    "print(\"Validation (PGD):\", accuracy(pgd_model, val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90130d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_adv_acc(model, loader, attack='fgsm', eps=EPS, alpha=None, steps=20):\n",
    "    model.eval(); loss_fn = nn.CrossEntropyLoss(); tot=ok=0\n",
    "    for xb, yb in loader:\n",
    "        if attack=='fgsm':\n",
    "            xb_adv = fgsm_attack(xb, yb, model, loss_fn, eps=eps)\n",
    "        else:\n",
    "            a = alpha if alpha is not None else eps/4\n",
    "            xb_adv = pgd_attack(xb, yb, model, loss_fn, eps=eps, alpha=a, steps=steps)\n",
    "        with torch.no_grad():\n",
    "            pred = model(xb_adv.to(device)).argmax(1).cpu()\n",
    "        ok += (pred == yb).sum().item(); tot += yb.size(0)\n",
    "    return ok/tot\n",
    "\n",
    "# Comprehensive evaluation metrics\n",
    "clean_e = accuracy(egeat_model, test_loader)\n",
    "fgsm_e = eval_adv_acc(egeat_model, test_loader, 'fgsm')\n",
    "pgd_e = eval_adv_acc(egeat_model, test_loader, 'pgd', steps=20)\n",
    "clean_s = accuracy(egeat_soup, test_loader)\n",
    "fgsm_s = eval_adv_acc(egeat_soup, test_loader, 'fgsm')\n",
    "pgd_s = eval_adv_acc(egeat_soup, test_loader, 'pgd', steps=20)\n",
    "clean_p = accuracy(pgd_model, test_loader)\n",
    "fgsm_p = eval_adv_acc(pgd_model, test_loader, 'fgsm')\n",
    "pgd_p = eval_adv_acc(pgd_model, test_loader, 'pgd', steps=20)\n",
    "\n",
    "# Display metrics in a professional table format\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPREHENSIVE EVALUATION METRICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Model':<20} {'Clean Acc':<12} {'FGSM Acc':<12} {'PGD-20 Acc':<12}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'EGEAT Model':<20} {clean_e:.4f}      {fgsm_e:.4f}      {pgd_e:.4f}\")\n",
    "print(f\"{'EGEAT Soup':<20} {clean_s:.4f}      {fgsm_s:.4f}      {pgd_s:.4f}\")\n",
    "print(f\"{'PGD Model':<20} {clean_p:.4f}      {fgsm_p:.4f}      {pgd_p:.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Visual metrics comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "models = ['EGEAT\\nModel', 'EGEAT\\nSoup', 'PGD\\nModel']\n",
    "x = np.arange(len(models))\n",
    "width = 0.25\n",
    "\n",
    "clean_accs = [clean_e, clean_s, clean_p]\n",
    "fgsm_accs = [fgsm_e, fgsm_s, fgsm_p]\n",
    "pgd_accs = [pgd_e, pgd_s, pgd_p]\n",
    "\n",
    "bars1 = ax.bar(x - width, clean_accs, width, label='Clean', color=PALETTE[\"primary\"], \n",
    "               edgecolor=PALETTE[\"text\"], linewidth=1.5, alpha=0.9)\n",
    "bars2 = ax.bar(x, fgsm_accs, width, label='FGSM', color=PALETTE[\"accent1\"], \n",
    "               edgecolor=PALETTE[\"text\"], linewidth=1.5, alpha=0.9)\n",
    "bars3 = ax.bar(x + width, pgd_accs, width, label='PGD-20', color=PALETTE[\"accent2\"], \n",
    "               edgecolor=PALETTE[\"text\"], linewidth=1.5, alpha=0.9)\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "               f'{height:.3f}', ha='center', va='bottom', \n",
    "               color=PALETTE[\"text\"], fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Model', fontsize=14, color=PALETTE[\"text\"], fontweight='medium')\n",
    "ax.set_ylabel('Accuracy', fontsize=14, color=PALETTE[\"text\"], fontweight='medium')\n",
    "ax.set_title('Model Performance: Clean vs Adversarial Accuracy', \n",
    "            fontsize=16, fontweight='bold', color=PALETTE[\"text\"], pad=20)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models, color=PALETTE[\"text\"], fontsize=12)\n",
    "ax.legend(loc='upper right', frameon=True, facecolor=DARK_THEME[\"axes.facecolor\"], \n",
    "         edgecolor=PALETTE[\"primary\"], labelcolor=PALETTE[\"text\"], fontsize=12)\n",
    "ax.set_ylim(0, 1.0)\n",
    "apply_dark_style(ax)\n",
    "plt.tight_layout()\n",
    "savefig(\"fig_comprehensive_metrics.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110a3bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gradient similarity - Enhanced with dark theme\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "models = [egeat_model.eval(), egeat_soup.eval(), pgd_model.eval()]\n",
    "names  = [\"EGEAT Model\", \"EGEAT Soup\", \"PGD Model\"]\n",
    "xb, yb = next(iter(test_loader)); xb, yb = xb.to(device), yb.to(device)\n",
    "grads = []\n",
    "for m in models:\n",
    "    m.zero_grad(set_to_none=True)\n",
    "    x_ = xb.detach().clone().requires_grad_(True)\n",
    "    loss = loss_fn(m(x_), yb); loss.backward()\n",
    "    grads.append(x_.grad.detach())\n",
    "\n",
    "def pairwise_cos(grads):\n",
    "    M=len(grads); mat=torch.zeros(M,M)\n",
    "    for i in range(M):\n",
    "        for j in range(M):\n",
    "            mat[i,j] = cos_sim(grads[i], grads[j]).detach().cpu()\n",
    "    return mat.numpy()\n",
    "\n",
    "G = pairwise_cos(grads)\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "im = ax.imshow(G, interpolation='nearest', cmap='viridis', vmin=0, vmax=1)\n",
    "ax.set_xticks(range(len(names)))\n",
    "ax.set_xticklabels(names, rotation=45, ha='right', color=PALETTE[\"text\"])\n",
    "ax.set_yticks(range(len(names)))\n",
    "ax.set_yticklabels(names, color=PALETTE[\"text\"])\n",
    "ax.set_title(\"Gradient Subspace Similarity Matrix\", fontsize=16, fontweight='bold', color=PALETTE[\"text\"], pad=20)\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(names)):\n",
    "    for j in range(len(names)):\n",
    "        text = ax.text(j, i, f'{G[i, j]:.3f}', ha=\"center\", va=\"center\", \n",
    "                      color=\"white\" if G[i, j] < 0.5 else \"black\", fontweight='bold')\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('Cosine Similarity', color=PALETTE[\"text\"], fontsize=12)\n",
    "cbar.ax.yaxis.set_tick_params(color=PALETTE[\"text_secondary\"])\n",
    "cbar.outline.set_edgecolor(PALETTE[\"primary\"])\n",
    "\n",
    "apply_dark_style(ax)\n",
    "plt.tight_layout()\n",
    "savefig(\"fig_gradient_similarity.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac9971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loss surface\n",
    "def get_vec(m): return torch.cat([p.detach().view(-1) for p in m.parameters()])\n",
    "def set_vec(m, v):\n",
    "    i=0\n",
    "    for p in m.parameters():\n",
    "        n=p.numel(); p.data.copy_(v[i:i+n].view_as(p)); i+=n\n",
    "\n",
    "base = copy.deepcopy(egeat_model).eval().to(device)\n",
    "w = get_vec(base); d1, d2 = torch.randn_like(w), torch.randn_like(w); d1/=d1.norm()+1e-12; d2/=d2.norm()+1e-12\n",
    "grid=21; alphas=torch.linspace(-0.5,0.5,grid); betas=torch.linspace(-0.5,0.5,grid); Z=np.zeros((grid,grid),dtype=np.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    xb_s, yb_s = xb[:min(128, xb.size(0))], yb[:min(128, yb.size(0))]\n",
    "    for i,a in enumerate(alphas):\n",
    "        for j,b in enumerate(betas):\n",
    "            tmp = copy.deepcopy(base).to(device); set_vec(tmp, w + a*d1 + b*d2)\n",
    "            Z[i,j] = nn.CrossEntropyLoss()(tmp(xb_s), yb_s).item()\n",
    "\n",
    "# Loss surface - Enhanced with dark theme\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "cs = ax.contourf(alphas.cpu(), betas.cpu(), Z.T, levels=30, cmap='plasma', alpha=0.9)\n",
    "contours = ax.contour(alphas.cpu(), betas.cpu(), Z.T, levels=15, colors='white', linewidths=1.2, alpha=0.4)\n",
    "ax.clabel(contours, inline=True, fontsize=9, colors='white', fmt='%.2f')\n",
    "ax.set_xlabel(\"α (Direction 1)\", fontsize=14, color=PALETTE[\"text\"], fontweight='medium')\n",
    "ax.set_ylabel(\"β (Direction 2)\", fontsize=14, color=PALETTE[\"text\"], fontweight='medium')\n",
    "ax.set_title(\"Loss Landscape Around EGEAT Model\", fontsize=16, fontweight='bold', color=PALETTE[\"text\"], pad=20)\n",
    "cbar = plt.colorbar(cs, ax=ax)\n",
    "cbar.set_label('Cross-Entropy Loss', color=PALETTE[\"text\"], fontsize=12, fontweight='medium')\n",
    "cbar.ax.yaxis.set_tick_params(color=PALETTE[\"text_secondary\"])\n",
    "cbar.outline.set_edgecolor(PALETTE[\"primary\"])\n",
    "apply_dark_style(ax)\n",
    "plt.tight_layout()\n",
    "savefig(\"fig_loss_surface.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968dfa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adversarial example grid\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "idxs = torch.arange(0, min(10, xb.size(0))); xv, yv = xb[idxs].detach().cpu(), yb[idxs].detach().cpu()\n",
    "x_fgsm_pgd = fgsm_attack(xv, yv, pgd_model, loss_fn, eps=EPS).cpu()\n",
    "x_exact_e  = exact_perturbation(xv, yv, egeat_model, loss_fn, eps=EPS, p='linf').cpu()\n",
    "\n",
    "def show_triplet(orig, a, b, title_a=\"FGSM (PGD)\", title_b=\"Exact (EGEAT)\"):\n",
    "    n=orig.size(0)\n",
    "    fig, axes = plt.subplots(3, n, figsize=(1.5*n, 4.5))\n",
    "    fig.patch.set_facecolor(DARK_THEME[\"figure.facecolor\"])\n",
    "    \n",
    "    for i in range(n):\n",
    "        im0=orig[i].permute(1,2,0).squeeze().numpy()\n",
    "        im1=a[i].permute(1,2,0).squeeze().numpy()\n",
    "        im2=b[i].permute(1,2,0).squeeze().numpy()\n",
    "        \n",
    "        # Handle grayscale images\n",
    "        if len(im0.shape) == 2:\n",
    "            im0 = np.stack([im0]*3, axis=-1)\n",
    "        if len(im1.shape) == 2:\n",
    "            im1 = np.stack([im1]*3, axis=-1)\n",
    "        if len(im2.shape) == 2:\n",
    "            im2 = np.stack([im2]*3, axis=-1)\n",
    "        \n",
    "        axes[0,i].imshow(np.clip(im0, 0, 1), vmin=0, vmax=1)\n",
    "        axes[0,i].axis(\"off\")\n",
    "        axes[0,i].set_facecolor(DARK_THEME[\"axes.facecolor\"])\n",
    "        \n",
    "        axes[1,i].imshow(np.clip(im1, 0, 1), vmin=0, vmax=1)\n",
    "        axes[1,i].axis(\"off\")\n",
    "        axes[1,i].set_facecolor(DARK_THEME[\"axes.facecolor\"])\n",
    "        \n",
    "        axes[2,i].imshow(np.clip(im2, 0, 1), vmin=0, vmax=1)\n",
    "        axes[2,i].axis(\"off\")\n",
    "        axes[2,i].set_facecolor(DARK_THEME[\"axes.facecolor\"])\n",
    "    \n",
    "    axes[0,0].set_ylabel(\"Original\", fontsize=12, color=PALETTE[\"text\"], fontweight='bold', rotation=0, ha='right', va='center')\n",
    "    axes[1,0].set_ylabel(title_a, fontsize=12, color=PALETTE[\"accent1\"], fontweight='bold', rotation=0, ha='right', va='center')\n",
    "    axes[2,0].set_ylabel(title_b, fontsize=12, color=PALETTE[\"accent2\"], fontweight='bold', rotation=0, ha='right', va='center')\n",
    "    \n",
    "    fig.suptitle(\"Adversarial Examples Comparison\", fontsize=16, fontweight='bold', color=PALETTE[\"text\"], y=0.98)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    savefig(\"fig_adversarial_grid.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "show_triplet(xv, x_fgsm_pgd, x_exact_e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93741af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transferability\n",
    "def transfer_rate(src, tgt, loader, eps=EPS):\n",
    "    loss_fn = nn.CrossEntropyLoss(); total=fooled=0\n",
    "    for xb, yb in loader:\n",
    "        xb_adv = fgsm_attack(xb, yb, src, loss_fn, eps=eps)\n",
    "        with torch.no_grad(): pred = tgt(xb_adv.to(device)).argmax(1).cpu()\n",
    "        fooled += (pred != yb).sum().item(); total += yb.size(0)\n",
    "    return fooled/total\n",
    "\n",
    "models = [egeat_model.eval(), egeat_soup.eval(), pgd_model.eval()]\n",
    "names  = [\"EGEAT model\", \"EGEAT soup\", \"PGD model\"]\n",
    "pairs = [(0,1),(0,2),(1,2)]; rates=[]\n",
    "for i,j in pairs:\n",
    "    r = transfer_rate(models[i], models[j], test_loader, eps=EPS); rates.append(r); print(f\"{names[i]}→{names[j]}: {r:.3f}\")\n",
    "\n",
    "# Transferability - Enhanced with dark theme\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "xs = np.arange(len(pairs))\n",
    "bars = ax.bar(xs, rates, color=[COLORS[i % len(COLORS)] for i in range(len(rates))], \n",
    "              edgecolor=PALETTE[\"primary\"], linewidth=2, alpha=0.85)\n",
    "ax.set_xticks(xs)\n",
    "ax.set_xticklabels([f\"{names[i]} → {names[j]}\" for i,j in pairs], \n",
    "                   rotation=25, ha='right', color=PALETTE[\"text\"], fontsize=12)\n",
    "ax.set_ylabel(\"Transfer Rate $P_T$\", fontsize=14, color=PALETTE[\"text\"], fontweight='medium')\n",
    "ax.set_title(\"Adversarial Transferability Across Models\", fontsize=16, fontweight='bold', \n",
    "            color=PALETTE[\"text\"], pad=20)\n",
    "ax.set_ylim(0, max(rates) * 1.15)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, rate) in enumerate(zip(bars, rates)):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "           f'{rate:.3f}', ha='center', va='bottom', \n",
    "           color=PALETTE[\"text\"], fontsize=11, fontweight='bold')\n",
    "\n",
    "apply_dark_style(ax)\n",
    "plt.tight_layout()\n",
    "savefig(\"fig_transfer.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75627a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ablation\n",
    "import pandas as pd\n",
    "ABL_SETTINGS=[(0.00,0.00),(0.10,0.00),(0.10,0.05),(0.20,0.05)]\n",
    "ABL_EPOCHS=20  # set to 100 for strict replication\n",
    "\n",
    "def quick_egeat(lg, ls, epochs=ABL_EPOCHS):\n",
    "    cfg = EGEATConfig(epochs=epochs, eps=EPS, lambda_geom=lg, lambda_soup=ls, snapshots_k=5, lr=2e-4)\n",
    "    m,s = train_egeat(cfg)\n",
    "    clean = accuracy(m, test_loader)\n",
    "    pgd20 = eval_adv_acc(m, test_loader, 'pgd', eps=EPS, steps=20)\n",
    "    m.eval(); ent=[]\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            p = F.softmax(m(xb.to(device)), dim=1).cpu().numpy()\n",
    "            ent.append(-(p*np.log(p+1e-12)).sum(axis=1))\n",
    "    ent = np.concatenate(ent); ece_proxy=float(ent.mean())\n",
    "    return clean, pgd20, ece_proxy\n",
    "\n",
    "rows=[]\n",
    "for lg, ls in ABL_SETTINGS:\n",
    "    print(f\"[Ablation] λ1={lg} λ2={ls}\")\n",
    "    c,p20,ece = quick_egeat(lg, ls, epochs=ABL_EPOCHS)\n",
    "    rows.append((lg, ls, c, p20, ece))\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"lambda1\",\"lambda2\",\"Acc_clean\",\"Acc_PGD20\",\"ECE_proxy\"])\n",
    "print(df)\n",
    "csv_path = os.path.join(SAVE_DIR, \"table_ablation_results.csv\"); df.to_csv(csv_path, index=False); print(\"Saved:\", csv_path)\n",
    "\n",
    "# Ablation study - Enhanced with dark theme\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot 1: Effect of λ1 on PGD-20 accuracy\n",
    "ax1.plot(df[\"lambda1\"], df[\"Acc_PGD20\"], marker=\"o\", linewidth=3, markersize=10, \n",
    "        color=PALETTE[\"primary\"], markerfacecolor=PALETTE[\"accent1\"], \n",
    "        markeredgecolor=PALETTE[\"primary\"], markeredgewidth=2)\n",
    "ax1.set_xlabel(\"λ₁ (Geometric Regularization)\", fontsize=14, color=PALETTE[\"text\"], fontweight='medium')\n",
    "ax1.set_ylabel(\"PGD-20 Accuracy\", fontsize=14, color=PALETTE[\"text\"], fontweight='medium')\n",
    "ax1.set_title(\"Effect of Geometric Regularization\", fontsize=15, fontweight='bold', \n",
    "             color=PALETTE[\"text\"], pad=15)\n",
    "ax1.grid(True, alpha=0.3, color=PALETTE[\"text_secondary\"])\n",
    "apply_dark_style(ax1)\n",
    "\n",
    "# Plot 2: Clean vs Robust accuracy trade-off\n",
    "ax2.scatter(df[\"Acc_clean\"], df[\"Acc_PGD20\"], s=200, alpha=0.8, \n",
    "           c=[COLORS[i % len(COLORS)] for i in range(len(df))],\n",
    "           edgecolors=PALETTE[\"primary\"], linewidths=2)\n",
    "for i, row in df.iterrows():\n",
    "    ax2.annotate(f'λ₁={row[\"lambda1\"]:.2f}\\nλ₂={row[\"lambda2\"]:.2f}', \n",
    "                (row[\"Acc_clean\"], row[\"Acc_PGD20\"]),\n",
    "                xytext=(5, 5), textcoords='offset points',\n",
    "                fontsize=10, color=PALETTE[\"text_secondary\"])\n",
    "ax2.set_xlabel(\"Clean Accuracy\", fontsize=14, color=PALETTE[\"text\"], fontweight='medium')\n",
    "ax2.set_ylabel(\"PGD-20 Accuracy\", fontsize=14, color=PALETTE[\"text\"], fontweight='medium')\n",
    "ax2.set_title(\"Clean vs Robust Accuracy Trade-off\", fontsize=15, fontweight='bold', \n",
    "             color=PALETTE[\"text\"], pad=15)\n",
    "ax2.grid(True, alpha=0.3, color=PALETTE[\"text_secondary\"])\n",
    "apply_dark_style(ax2)\n",
    "\n",
    "plt.suptitle(\"Ablation Study: Hyperparameter Effects\", fontsize=17, fontweight='bold', \n",
    "            color=PALETTE[\"text\"], y=1.02)\n",
    "plt.tight_layout()\n",
    "savefig(\"fig_ablation.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64723e42",
   "metadata": {},
   "source": [
    "\n",
    "# === BLOG / LINKEDIN VISUALS — Modern Showcase ===\n",
    "\n",
    "The following cells generate **publication-quality** and **social-ready** visuals (1080×1080) with a modern dark theme.\n",
    "They reuse the trained models (`egeat_model`, `egeat_soup`, `pgd_model`) and the dataset/test loader from above.\n",
    "All outputs are saved to: `os.path.join(SAVE_DIR, \"blog_visuals\")`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb9a513",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Showcase visualizations directory (uses existing dark theme from cell 1)\n",
    "BLOG_DIR = os.path.join(SAVE_DIR, \"blog_visuals\")\n",
    "os.makedirs(BLOG_DIR, exist_ok=True)\n",
    "\n",
    "def save_square_png(name, fig=None, size=12):\n",
    "    \"\"\"Save square figure for social media (1080×1080 equivalent)\"\"\"\n",
    "    if fig is None:\n",
    "        fig = plt.gcf()\n",
    "    fig.set_size_inches(size, size)\n",
    "    path = os.path.join(BLOG_DIR, name)\n",
    "    fig.savefig(path, bbox_inches=\"tight\", dpi=300, \n",
    "                facecolor=DARK_THEME[\"figure.facecolor\"],\n",
    "                edgecolor=\"none\")\n",
    "    print(f\"✓ Saved showcase: {path}\")\n",
    "\n",
    "print(f\"✓ Showcase directory ready: {BLOG_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Loss Landscape \"Evolution\": sweep along two random directions around EGEAT θ\n",
    "# Produces a strip of frames that can be combined into a GIF (kept simple as a strip for portability).\n",
    "import copy, torch, torch.nn as nn\n",
    "\n",
    "def get_vec(m): \n",
    "    return torch.cat([p.detach().view(-1) for p in m.parameters()])\n",
    "\n",
    "def set_vec(m, v):\n",
    "    i=0\n",
    "    for p in m.parameters():\n",
    "        n = p.numel()\n",
    "        p.data.copy_(v[i:i+n].view_as(p)); i+=n\n",
    "\n",
    "base = copy.deepcopy(egeat_model).eval().to(device)\n",
    "w = get_vec(base)\n",
    "d1, d2 = torch.randn_like(w), torch.randn_like(w)\n",
    "d1 /= (d1.norm()+1e-12); d2 /= (d2.norm()+1e-12)\n",
    "\n",
    "grid = 9\n",
    "alphas = torch.linspace(-0.6, 0.6, grid)\n",
    "betas  = torch.linspace(-0.6, 0.6, grid)\n",
    "Z = np.zeros((grid, grid), dtype=np.float32)\n",
    "\n",
    "xb, yb = next(iter(test_loader))\n",
    "xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    xb_s, yb_s = xb[:min(256, xb.size(0))], yb[:min(256, yb.size(0))]\n",
    "    for i,a in enumerate(alphas):\n",
    "        for j,b in enumerate(betas):\n",
    "            tmp = copy.deepcopy(base).to(device)\n",
    "            set_vec(tmp, w + a*d1 + b*d2)\n",
    "            Z[i,j] = nn.CrossEntropyLoss()(tmp(xb_s), yb_s).item()\n",
    "\n",
    "# Render as a modern contour with bright strokes - Enhanced dark theme\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cs = ax.contourf(alphas.cpu(), betas.cpu(), Z.T, levels=30, cmap='plasma', alpha=0.95)\n",
    "contours = ax.contour(alphas.cpu(), betas.cpu(), Z.T, levels=15, colors='white', \n",
    "                     linewidths=1.5, alpha=0.5)\n",
    "ax.clabel(contours, inline=True, fontsize=10, colors='white', fmt='%.2f', fontweight='bold')\n",
    "ax.set_xlabel(\"α (Direction 1)\", fontsize=16, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax.set_ylabel(\"β (Direction 2)\", fontsize=16, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax.set_title(\"Loss Landscape Around EGEAT Model\", fontsize=18, fontweight='bold', \n",
    "            color=PALETTE[\"text\"], pad=25)\n",
    "cbar = plt.colorbar(cs, ax=ax)\n",
    "cbar.set_label('Cross-Entropy Loss', color=PALETTE[\"text\"], fontsize=14, fontweight='bold')\n",
    "cbar.ax.yaxis.set_tick_params(color=PALETTE[\"text_secondary\"], labelsize=12)\n",
    "cbar.outline.set_edgecolor(PALETTE[\"primary\"])\n",
    "cbar.outline.set_linewidth(2)\n",
    "apply_dark_style(ax)\n",
    "plt.tight_layout()\n",
    "save_square_png(\"loss_landscape_showcase.png\", fig=fig, size=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df5a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Gradient Flow Constellation: PCA of ∇_x ℓ over test mini-batches for multiple models\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "models = [egeat_model.eval(), egeat_soup.eval(), pgd_model.eval()]\n",
    "names  = [\"EGEAT\", \"Soup\", \"PGD\"]\n",
    "\n",
    "# Sample multiple mini-batches to build a gradient cloud\n",
    "grads_all = []\n",
    "labels_all = []\n",
    "num_batches = 6\n",
    "it = iter(test_loader)\n",
    "for b in range(num_batches):\n",
    "    try:\n",
    "        xb, yb = next(it)\n",
    "    except StopIteration:\n",
    "        break\n",
    "    xb, yb = xb.to(device), yb.to(device)\n",
    "    for idx, m in enumerate(models):\n",
    "        m.zero_grad(set_to_none=True)\n",
    "        x_ = xb.detach().clone().requires_grad_(True)\n",
    "        loss = loss_fn(m(x_), yb); loss.backward()\n",
    "        g = x_.grad.detach().view(x_.size(0), -1).cpu().numpy()\n",
    "        grads_all.append(g)\n",
    "        labels_all += [names[idx]] * g.shape[0]\n",
    "\n",
    "G = np.concatenate(grads_all, axis=0)\n",
    "pca = PCA(n_components=2, random_state=42).fit(G)\n",
    "P = pca.transform(G)\n",
    "\n",
    "# Gradient constellation - Enhanced dark theme\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "for name, color in zip(names, COLORS[:len(names)]):\n",
    "    mask = np.array(labels_all) == name\n",
    "    ax.scatter(P[mask,0], P[mask,1], s=25, alpha=0.7, label=name, c=color, \n",
    "              edgecolors=PALETTE[\"primary\"], linewidths=0.5)\n",
    "ax.legend(frameon=True, facecolor=DARK_THEME[\"axes.facecolor\"], \n",
    "         edgecolor=PALETTE[\"primary\"], labelcolor=PALETTE[\"text\"], \n",
    "         fontsize=14, loc='best', framealpha=0.9)\n",
    "ax.set_title(\"Gradient Constellation (PCA) — Decorrelated Subspaces\", \n",
    "            fontsize=18, fontweight='bold', color=PALETTE[\"text\"], pad=25)\n",
    "ax.set_xlabel(\"Principal Component 1\", fontsize=16, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax.set_ylabel(\"Principal Component 2\", fontsize=16, color=PALETTE[\"text\"], fontweight='bold')\n",
    "apply_dark_style(ax)\n",
    "plt.tight_layout()\n",
    "save_square_png(\"gradient_constellation.png\", fig=fig, size=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4691e18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Adversarial Transfer Graph: edges weighted by transfer rate P_T\n",
    "import networkx as nx\n",
    "\n",
    "def transfer_rate(source_model, target_model, loader, eps=float(EPS)):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    total=fooled=0\n",
    "    for xb, yb in loader:\n",
    "        xb_adv = fgsm_attack(xb, yb, source_model, loss_fn, eps=eps)\n",
    "        with torch.no_grad():\n",
    "            pred_t = target_model(xb_adv.to(device)).argmax(1).cpu()\n",
    "        fooled += (pred_t != yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "    return fooled/total\n",
    "\n",
    "models = [egeat_model.eval(), egeat_soup.eval(), pgd_model.eval()]\n",
    "names  = [\"EGEAT\", \"Soup\", \"PGD\"]\n",
    "\n",
    "Gx = nx.DiGraph()\n",
    "for n in names:\n",
    "    Gx.add_node(n)\n",
    "\n",
    "edges = []\n",
    "for i, si in enumerate(names):\n",
    "    for j, tj in enumerate(names):\n",
    "        if i==j: continue\n",
    "        r = transfer_rate(models[i], models[j], test_loader, eps=float(EPS))\n",
    "        Gx.add_edge(si, tj, weight=r)\n",
    "        edges.append((si, tj, r))\n",
    "\n",
    "# Layout & draw - Enhanced dark theme\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "pos = nx.circular_layout(Gx)\n",
    "weights = [Gx[u][v]['weight'] for u,v in Gx.edges()]\n",
    "w_scaled = [(1.0 + 8*w) for w in weights]  # emphasize thickness\n",
    "nx.draw_networkx_nodes(Gx, pos, node_size=2800, node_color=COLORS[:3], \n",
    "                       linewidths=3, edgecolors=PALETTE[\"primary\"], ax=ax)\n",
    "nx.draw_networkx_labels(Gx, pos, font_size=18, font_color=PALETTE[\"text\"], \n",
    "                        font_weight='bold', ax=ax)\n",
    "nx.draw_networkx_edges(Gx, pos, width=w_scaled, edge_color=PALETTE[\"accent1\"], \n",
    "                       arrows=True, arrowsize=25, connectionstyle='arc3,rad=0.15',\n",
    "                       alpha=0.8, ax=ax)\n",
    "\n",
    "# Annotate edge weights\n",
    "for (u,v,r) in edges:\n",
    "    x=(pos[u][0]+pos[v][0])/2\n",
    "    y=(pos[u][1]+pos[v][1])/2\n",
    "    ax.text(x, y, f\"{r:.3f}\", ha=\"center\", va=\"center\", \n",
    "           fontsize=13, color=PALETTE[\"text\"], fontweight='bold',\n",
    "           bbox=dict(boxstyle='round,pad=0.3', facecolor=DARK_THEME[\"axes.facecolor\"], \n",
    "                    edgecolor=PALETTE[\"primary\"], alpha=0.8))\n",
    "\n",
    "ax.set_title(\"Adversarial Transfer Graph\\n(Lower Transfer Rate = Better Robustness)\", \n",
    "            fontsize=18, fontweight='bold', color=PALETTE[\"text\"], pad=25)\n",
    "ax.axis(\"off\")\n",
    "apply_dark_style(ax)\n",
    "plt.tight_layout()\n",
    "save_square_png(\"transfer_graph.png\", fig=fig, size=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b67e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Variance vs Ensemble Size K: empirical variance of adversarial loss across K-model soups\n",
    "# If snapshot list isn't available from training, we quickly generate extra snapshots by light finetuning copies.\n",
    "import copy, torch\n",
    "\n",
    "def collect_snapshots(base_model, k=5, steps=100):\n",
    "    snaps = [copy.deepcopy(base_model).to(device).eval()]\n",
    "    opt = torch.optim.SGD(base_model.parameters(), lr=1e-3, momentum=0.9)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    it = iter(train_loader)\n",
    "    for i in range(1, k):\n",
    "        # light finetune from previous snapshot to diversify\n",
    "        for _ in range(steps):\n",
    "            try:\n",
    "                xb, yb = next(it)\n",
    "            except StopIteration:\n",
    "                it = iter(train_loader)\n",
    "                xb, yb = next(it)\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss = loss_fn(base_model(xb), yb); loss.backward(); opt.step()\n",
    "        snaps.append(copy.deepcopy(base_model).to(device).eval())\n",
    "    return snaps\n",
    "\n",
    "def soup(models):\n",
    "    base = copy.deepcopy(models[0]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for p in base.parameters(): p.data.zero_()\n",
    "        for m in models:\n",
    "            for pb, pm in zip(base.parameters(), m.parameters()):\n",
    "                pb.add_(pm.data)\n",
    "        for p in base.parameters(): p.data.div_(len(models))\n",
    "    return base\n",
    "\n",
    "def adv_loss_on_loader(model, loader, eps=float(EPS)):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    total=[]; \n",
    "    for xb, yb in loader:\n",
    "        xb_adv = fgsm_attack(xb, yb, model, loss_fn, eps=eps)\n",
    "        with torch.no_grad():\n",
    "            l = loss_fn(model(xb_adv.to(device)), yb.to(device)).item()\n",
    "        total.append(l)\n",
    "    return np.array(total)\n",
    "\n",
    "# collect snapshots from EGEAT model\n",
    "snaps = collect_snapshots(copy.deepcopy(egeat_model).to(device).train(), k=5, steps=50)\n",
    "Ks = [1,2,3,4,5]\n",
    "variances = []\n",
    "for k in Ks:\n",
    "    S = soup(snaps[:k])\n",
    "    losses = adv_loss_on_loader(S, test_loader, eps=float(EPS))\n",
    "    variances.append(float(np.var(losses)))\n",
    "\n",
    "# Variance vs ensemble size - Enhanced dark theme\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.plot(Ks, variances, marker=\"o\", linewidth=4, markersize=14, \n",
    "       color=PALETTE[\"primary\"], markerfacecolor=PALETTE[\"accent1\"], \n",
    "       markeredgecolor=PALETTE[\"primary\"], markeredgewidth=3, alpha=0.9)\n",
    "ax.fill_between(Ks, variances, alpha=0.3, color=PALETTE[\"primary\"])\n",
    "ax.set_xlabel(\"Ensemble Size K\", fontsize=16, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax.set_ylabel(\"Var[ Adversarial Loss ]\", fontsize=16, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax.set_title(\"Variance vs Ensemble Size (EGEAT Parameter Soups)\", \n",
    "            fontsize=18, fontweight='bold', color=PALETTE[\"text\"], pad=25)\n",
    "\n",
    "# Add value labels\n",
    "for k, var in zip(Ks, variances):\n",
    "    ax.text(k, var, f'{var:.4f}', ha='center', va='bottom', \n",
    "           color=PALETTE[\"text\"], fontsize=12, fontweight='bold')\n",
    "\n",
    "apply_dark_style(ax)\n",
    "plt.tight_layout()\n",
    "save_square_png(\"variance_vs_k.png\", fig=fig, size=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e00ecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) 3D λ1–λ2 trade-off surface (clean vs robust accuracy)\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "import torch\n",
    "\n",
    "grid_l1 = np.linspace(0.0, 0.2, 4)   # [0.00, 0.067, 0.133, 0.2]\n",
    "grid_l2 = np.linspace(0.00, 0.08, 4) # [0.00, 0.027, 0.053, 0.08]\n",
    "\n",
    "Acc_clean = np.zeros((len(grid_l1), len(grid_l2)))\n",
    "Acc_pgd20 = np.zeros((len(grid_l1), len(grid_l2)))\n",
    "\n",
    "def train_quick(l1, l2, epochs=15):\n",
    "    cfg = EGEATConfig(epochs=epochs, eps=float(EPS), lambda_geom=float(l1), lambda_soup=float(l2), snapshots_k=3, lr=2e-4)\n",
    "    m, _ = train_egeat(cfg)\n",
    "    ac = accuracy(m, test_loader)\n",
    "    ar = eval_adv_acc(m, test_loader, attack='pgd', eps=float(EPS), steps=20)\n",
    "    return ac, ar\n",
    "\n",
    "for i, l1 in enumerate(grid_l1):\n",
    "    for j, l2 in enumerate(grid_l2):\n",
    "        print(f\"[λ-surface] λ1={l1:.3f}, λ2={l2:.3f}\")\n",
    "        ac, ar = train_quick(l1, l2, epochs=12)\n",
    "        Acc_clean[i,j] = ac; Acc_pgd20[i,j] = ar\n",
    "\n",
    "# Clean surface - Enhanced dark theme\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "L1, L2 = np.meshgrid(grid_l1, grid_l2, indexing='ij')\n",
    "surf = ax.plot_surface(L1, L2, Acc_clean, linewidth=0, antialiased=True, \n",
    "                      alpha=0.95, cmap=\"viridis\", edgecolor='none')\n",
    "ax.set_xlabel(\"λ₁ (Geometric)\", fontsize=14, color=PALETTE[\"text\"], fontweight='bold', labelpad=10)\n",
    "ax.set_ylabel(\"λ₂ (Soup)\", fontsize=14, color=PALETTE[\"text\"], fontweight='bold', labelpad=10)\n",
    "ax.set_zlabel(\"Clean Accuracy\", fontsize=14, color=PALETTE[\"text\"], fontweight='bold', labelpad=10)\n",
    "ax.set_title(\"Hyperparameter Surface: Clean Accuracy\", fontsize=16, fontweight='bold', \n",
    "            color=PALETTE[\"text\"], pad=20)\n",
    "ax.xaxis.pane.fill = False\n",
    "ax.yaxis.pane.fill = False\n",
    "ax.zaxis.pane.fill = False\n",
    "ax.xaxis.pane.set_edgecolor(PALETTE[\"text_secondary\"])\n",
    "ax.yaxis.pane.set_edgecolor(PALETTE[\"text_secondary\"])\n",
    "ax.zaxis.pane.set_edgecolor(PALETTE[\"text_secondary\"])\n",
    "ax.tick_params(colors=PALETTE[\"text_secondary\"])\n",
    "cbar = fig.colorbar(surf, ax=ax, shrink=0.6)\n",
    "cbar.set_label('Clean Accuracy', color=PALETTE[\"text\"], fontsize=12, fontweight='bold')\n",
    "cbar.ax.yaxis.set_tick_params(color=PALETTE[\"text_secondary\"])\n",
    "save_square_png(\"lambda_surface_clean.png\", fig=fig, size=10)\n",
    "plt.show()\n",
    "\n",
    "# Robust surface - Enhanced dark theme\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "surf = ax.plot_surface(L1, L2, Acc_pgd20, linewidth=0, antialiased=True, \n",
    "                      alpha=0.95, cmap=\"plasma\", edgecolor='none')\n",
    "ax.set_xlabel(\"λ₁ (Geometric)\", fontsize=14, color=PALETTE[\"text\"], fontweight='bold', labelpad=10)\n",
    "ax.set_ylabel(\"λ₂ (Soup)\", fontsize=14, color=PALETTE[\"text\"], fontweight='bold', labelpad=10)\n",
    "ax.set_zlabel(\"PGD-20 Accuracy\", fontsize=14, color=PALETTE[\"text\"], fontweight='bold', labelpad=10)\n",
    "ax.set_title(\"Hyperparameter Surface: Robust Accuracy (PGD-20)\", fontsize=16, fontweight='bold', \n",
    "            color=PALETTE[\"text\"], pad=20)\n",
    "ax.xaxis.pane.fill = False\n",
    "ax.yaxis.pane.fill = False\n",
    "ax.zaxis.pane.fill = False\n",
    "ax.xaxis.pane.set_edgecolor(PALETTE[\"text_secondary\"])\n",
    "ax.yaxis.pane.set_edgecolor(PALETTE[\"text_secondary\"])\n",
    "ax.zaxis.pane.set_edgecolor(PALETTE[\"text_secondary\"])\n",
    "ax.tick_params(colors=PALETTE[\"text_secondary\"])\n",
    "cbar = fig.colorbar(surf, ax=ax, shrink=0.6)\n",
    "cbar.set_label('PGD-20 Accuracy', color=PALETTE[\"text\"], fontsize=12, fontweight='bold')\n",
    "cbar.ax.yaxis.set_tick_params(color=PALETTE[\"text_secondary\"])\n",
    "save_square_png(\"lambda_surface_robust.png\", fig=fig, size=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b72a869",
   "metadata": {},
   "source": [
    "## Summary: All Results and Metrics\n",
    "\n",
    "This section provides a comprehensive summary of all evaluation results with professional visualizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== COMPREHENSIVE RESULTS SUMMARY =====\n",
    "# Display all metrics in a professional dashboard format\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" \" * 20 + \"EGEAT EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Recompute all metrics for summary\n",
    "all_metrics = {\n",
    "    'EGEAT Model': {\n",
    "        'Clean': accuracy(egeat_model, test_loader),\n",
    "        'FGSM': eval_adv_acc(egeat_model, test_loader, 'fgsm'),\n",
    "        'PGD-20': eval_adv_acc(egeat_model, test_loader, 'pgd', steps=20)\n",
    "    },\n",
    "    'EGEAT Soup': {\n",
    "        'Clean': accuracy(egeat_soup, test_loader),\n",
    "        'FGSM': eval_adv_acc(egeat_soup, test_loader, 'fgsm'),\n",
    "        'PGD-20': eval_adv_acc(egeat_soup, test_loader, 'pgd', steps=20)\n",
    "    },\n",
    "    'PGD Model': {\n",
    "        'Clean': accuracy(pgd_model, test_loader),\n",
    "        'FGSM': eval_adv_acc(pgd_model, test_loader, 'fgsm'),\n",
    "        'PGD-20': eval_adv_acc(pgd_model, test_loader, 'pgd', steps=20)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Print formatted table\n",
    "print(f\"\\n{'Model':<20} {'Clean Acc':<15} {'FGSM Acc':<15} {'PGD-20 Acc':<15}\")\n",
    "print(\"-\"*80)\n",
    "for model_name, metrics in all_metrics.items():\n",
    "    print(f\"{model_name:<20} {metrics['Clean']:<15.4f} {metrics['FGSM']:<15.4f} {metrics['PGD-20']:<15.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comprehensive dashboard visualization\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "fig.patch.set_facecolor(DARK_THEME[\"figure.facecolor\"])\n",
    "\n",
    "# Create a 2x3 grid of subplots\n",
    "gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Accuracy comparison (bar chart)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "models_list = list(all_metrics.keys())\n",
    "clean_vals = [all_metrics[m]['Clean'] for m in models_list]\n",
    "fgsm_vals = [all_metrics[m]['FGSM'] for m in models_list]\n",
    "pgd_vals = [all_metrics[m]['PGD-20'] for m in models_list]\n",
    "x = np.arange(len(models_list))\n",
    "width = 0.25\n",
    "bars1 = ax1.bar(x - width, clean_vals, width, label='Clean', color=PALETTE[\"primary\"], \n",
    "                edgecolor=PALETTE[\"text\"], linewidth=1.5, alpha=0.9)\n",
    "bars2 = ax1.bar(x, fgsm_vals, width, label='FGSM', color=PALETTE[\"accent1\"], \n",
    "                edgecolor=PALETTE[\"text\"], linewidth=1.5, alpha=0.9)\n",
    "bars3 = ax1.bar(x + width, pgd_vals, width, label='PGD-20', color=PALETTE[\"accent2\"], \n",
    "                edgecolor=PALETTE[\"text\"], linewidth=1.5, alpha=0.9)\n",
    "ax1.set_ylabel('Accuracy', fontsize=12, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax1.set_title('Accuracy Comparison', fontsize=14, fontweight='bold', color=PALETTE[\"text\"])\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels([m.replace(' ', '\\n') for m in models_list], color=PALETTE[\"text\"], fontsize=10)\n",
    "ax1.legend(frameon=True, facecolor=DARK_THEME[\"axes.facecolor\"], edgecolor=PALETTE[\"primary\"], \n",
    "          labelcolor=PALETTE[\"text\"], fontsize=10)\n",
    "ax1.set_ylim(0, 1.0)\n",
    "apply_dark_style(ax1)\n",
    "\n",
    "# 2. Robustness comparison (radar/spider chart alternative - bar chart)\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "robustness = [all_metrics[m]['PGD-20'] for m in models_list]\n",
    "bars = ax2.barh(models_list, robustness, color=[COLORS[i % len(COLORS)] for i in range(len(models_list))],\n",
    "               edgecolor=PALETTE[\"primary\"], linewidth=2, alpha=0.85)\n",
    "for i, (bar, val) in enumerate(zip(bars, robustness)):\n",
    "    ax2.text(val + 0.01, i, f'{val:.3f}', va='center', color=PALETTE[\"text\"], \n",
    "            fontsize=11, fontweight='bold')\n",
    "ax2.set_xlabel('PGD-20 Accuracy', fontsize=12, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax2.set_title('Robustness Ranking', fontsize=14, fontweight='bold', color=PALETTE[\"text\"])\n",
    "ax2.set_xlim(0, 1.0)\n",
    "apply_dark_style(ax2)\n",
    "\n",
    "# 3. Performance improvement over baseline\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "baseline_pgd = all_metrics['PGD Model']['PGD-20']\n",
    "improvements = [\n",
    "    (all_metrics['EGEAT Model']['PGD-20'] - baseline_pgd) * 100,\n",
    "    (all_metrics['EGEAT Soup']['PGD-20'] - baseline_pgd) * 100\n",
    "]\n",
    "improvement_names = ['EGEAT\\nModel', 'EGEAT\\nSoup']\n",
    "colors_imp = [PALETTE[\"success\"] if imp > 0 else PALETTE[\"error\"] for imp in improvements]\n",
    "bars = ax3.barh(improvement_names, improvements, color=colors_imp, \n",
    "               edgecolor=PALETTE[\"primary\"], linewidth=2, alpha=0.85)\n",
    "for i, (bar, imp) in enumerate(zip(bars, improvements)):\n",
    "    ax3.text(imp + (0.5 if imp > 0 else -0.5), i, f'{imp:+.2f}%', va='center', \n",
    "            ha='left' if imp > 0 else 'right', color=PALETTE[\"text\"], \n",
    "            fontsize=11, fontweight='bold')\n",
    "ax3.axvline(0, color=PALETTE[\"text_secondary\"], linestyle='--', linewidth=1.5)\n",
    "ax3.set_xlabel('Improvement (%)', fontsize=12, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax3.set_title('Improvement over PGD Baseline', fontsize=14, fontweight='bold', color=PALETTE[\"text\"])\n",
    "apply_dark_style(ax3)\n",
    "\n",
    "# 4. Transferability heatmap\n",
    "ax4 = fig.add_subplot(gs[1, :2])\n",
    "transfer_matrix = np.zeros((len(models_list), len(models_list)))\n",
    "for i, src in enumerate(models_list):\n",
    "    for j, tgt in enumerate(models_list):\n",
    "        if i != j:\n",
    "            transfer_matrix[i, j] = transfer_rate(\n",
    "                [egeat_model, egeat_soup, pgd_model][i],\n",
    "                [egeat_model, egeat_soup, pgd_model][j],\n",
    "                test_loader, eps=EPS\n",
    "            )\n",
    "        else:\n",
    "            transfer_matrix[i, j] = 1.0  # Self-attack (always 100%)\n",
    "\n",
    "im = ax4.imshow(transfer_matrix, cmap='RdYlGn_r', vmin=0, vmax=1, aspect='auto')\n",
    "ax4.set_xticks(range(len(models_list)))\n",
    "ax4.set_xticklabels([m.replace(' ', '\\n') for m in models_list], color=PALETTE[\"text\"], fontsize=10)\n",
    "ax4.set_yticks(range(len(models_list)))\n",
    "ax4.set_yticklabels([m.replace(' ', '\\n') for m in models_list], color=PALETTE[\"text\"], fontsize=10)\n",
    "ax4.set_xlabel('Target Model', fontsize=12, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax4.set_ylabel('Source Model', fontsize=12, color=PALETTE[\"text\"], fontweight='bold')\n",
    "ax4.set_title('Adversarial Transferability Matrix', fontsize=14, fontweight='bold', color=PALETTE[\"text\"])\n",
    "\n",
    "# Add annotations\n",
    "for i in range(len(models_list)):\n",
    "    for j in range(len(models_list)):\n",
    "        text = ax4.text(j, i, f'{transfer_matrix[i, j]:.2f}', ha=\"center\", va=\"center\",\n",
    "                       color=\"white\" if transfer_matrix[i, j] < 0.5 else \"black\", \n",
    "                       fontweight='bold', fontsize=10)\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax4)\n",
    "cbar.set_label('Transfer Rate', color=PALETTE[\"text\"], fontsize=11, fontweight='bold')\n",
    "cbar.ax.yaxis.set_tick_params(color=PALETTE[\"text_secondary\"])\n",
    "cbar.outline.set_edgecolor(PALETTE[\"primary\"])\n",
    "apply_dark_style(ax4)\n",
    "\n",
    "# 5. Key statistics text box\n",
    "ax5 = fig.add_subplot(gs[1, 2])\n",
    "ax5.axis('off')\n",
    "stats_text = f\"\"\"\n",
    "KEY STATISTICS\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "Best Clean Accuracy:\n",
    "  {max(clean_vals):.4f} ({models_list[np.argmax(clean_vals)]})\n",
    "\n",
    "Best FGSM Accuracy:\n",
    "  {max(fgsm_vals):.4f} ({models_list[np.argmax(fgsm_vals)]})\n",
    "\n",
    "Best PGD-20 Accuracy:\n",
    "  {max(pgd_vals):.4f} ({models_list[np.argmax(pgd_vals)]})\n",
    "\n",
    "Average Robustness Gain:\n",
    "  {np.mean(improvements):+.2f}%\n",
    "\n",
    "Dataset: {DATASET}\n",
    "Epsilon: {EPS:.4f}\n",
    "\"\"\"\n",
    "ax5.text(0.1, 0.5, stats_text, transform=ax5.transAxes, fontsize=11,\n",
    "        color=PALETTE[\"text\"], verticalalignment='center',\n",
    "        family='monospace', fontweight='bold',\n",
    "        bbox=dict(boxstyle='round', facecolor=DARK_THEME[\"axes.facecolor\"],\n",
    "                 edgecolor=PALETTE[\"primary\"], linewidth=2, alpha=0.9))\n",
    "\n",
    "fig.suptitle('EGEAT: Complete Evaluation Dashboard', fontsize=20, fontweight='bold',\n",
    "            color=PALETTE[\"text\"], y=0.98)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "savefig(\"fig_complete_dashboard.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ All visualizations generated successfully!\")\n",
    "print(f\"✓ All figures saved to: {SAVE_DIR}\")\n",
    "print(f\"✓ Showcase figures saved to: {BLOG_DIR}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
