{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EGEAT: Ensemble Gradient-based Ensemble Adversarial Training\n",
        "\n",
        "This notebook runs the complete EGEAT experiment pipeline including:\n",
        "- Ensemble model training\n",
        "- Adversarial training with geometric regularization\n",
        "- Comprehensive evaluation metrics\n",
        "- Visualization of all diagrams and results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install torch torchvision numpy pandas matplotlib seaborn tqdm scikit-learn imageio -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard imports\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import logging\n",
        "import traceback\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Tuple, Union\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from copy import deepcopy\n",
        "\n",
        "# Set up paths for Colab\n",
        "WORK_DIR = '/content/EGEAT'\n",
        "os.makedirs(WORK_DIR, exist_ok=True)\n",
        "os.chdir(WORK_DIR)\n",
        "\n",
        "# Create directory structure\n",
        "os.makedirs('src', exist_ok=True)\n",
        "os.makedirs('src/attacks', exist_ok=True)\n",
        "os.makedirs('src/evaluation', exist_ok=True)\n",
        "os.makedirs('src/models', exist_ok=True)\n",
        "os.makedirs('src/training', exist_ok=True)\n",
        "os.makedirs('src/utils', exist_ok=True)\n",
        "\n",
        "print(f\"Working directory: {os.getcwd()}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Source Code Setup\n",
        "\n",
        "The following cells contain all the source code from the project organized by module.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Configuration Module\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# src/config.py\n",
        "from dataclasses import dataclass, asdict, field\n",
        "from typing import Optional\n",
        "import argparse\n",
        "\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    batch_size: int = 128\n",
        "    learning_rate: float = 2e-4\n",
        "    epochs: int = 5\n",
        "    lambda_geom: float = 0.1\n",
        "    lambda_soup: float = 0.05\n",
        "    epsilon: float = 8/255\n",
        "    use_mixed_precision: bool = False\n",
        "    num_workers: int = 2\n",
        "    pin_memory: bool = True\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    model_type: str = 'SimpleCNN'\n",
        "    input_channels: int = 3\n",
        "    num_classes: int = 10\n",
        "    ensemble_size: int = 5\n",
        "\n",
        "@dataclass\n",
        "class AttackConfig:\n",
        "    epsilon: float = 8/255\n",
        "    alpha: float = 2/255\n",
        "    pgd_iters: int = 10\n",
        "    cw_iters: int = 50\n",
        "    cw_c: float = 1e-2\n",
        "    cw_lr: float = 0.01\n",
        "\n",
        "@dataclass\n",
        "class EvaluationConfig:\n",
        "    max_batches: int = 10\n",
        "    n_bins_ece: int = 15\n",
        "    loss_landscape_grid_n: int = 21\n",
        "    loss_landscape_radius: float = 1.0\n",
        "\n",
        "@dataclass\n",
        "class DataConfig:\n",
        "    dataset: str = 'cifar10'\n",
        "    val_split: float = 0.1\n",
        "    augment: bool = True\n",
        "    data_path: str = './data'\n",
        "\n",
        "@dataclass\n",
        "class ExperimentConfig:\n",
        "    experiment_name: str = 'egeat_experiment'\n",
        "    seed: int = 42\n",
        "    device: Optional[str] = None\n",
        "    save_dir: str = 'results'\n",
        "    resume: bool = False\n",
        "    checkpoint_dir: Optional[str] = None\n",
        "    training: TrainingConfig = field(default_factory=TrainingConfig)\n",
        "    model: ModelConfig = field(default_factory=ModelConfig)\n",
        "    attack: AttackConfig = field(default_factory=AttackConfig)\n",
        "    evaluation: EvaluationConfig = field(default_factory=EvaluationConfig)\n",
        "    data: DataConfig = field(default_factory=DataConfig)\n",
        "    \n",
        "    def to_dict(self):\n",
        "        return asdict(self)\n",
        "    \n",
        "    @classmethod\n",
        "    def from_dict(cls, d):\n",
        "        training = TrainingConfig(**d.pop('training', {}))\n",
        "        model = ModelConfig(**d.pop('model', {}))\n",
        "        attack = AttackConfig(**d.pop('attack', {}))\n",
        "        evaluation = EvaluationConfig(**d.pop('evaluation', {}))\n",
        "        data = DataConfig(**d.pop('data', {}))\n",
        "        return cls(training=training, model=model, attack=attack, evaluation=evaluation, data=data, **d)\n",
        "    \n",
        "    def save(self, path: str):\n",
        "        os.makedirs(os.path.dirname(path) if os.path.dirname(path) else '.', exist_ok=True)\n",
        "        with open(path, 'w') as f:\n",
        "            json.dump(self.to_dict(), f, indent=2)\n",
        "    \n",
        "    @classmethod\n",
        "    def load(cls, path: str):\n",
        "        with open(path, 'r') as f:\n",
        "            d = json.load(f)\n",
        "        return cls.from_dict(d)\n",
        "\n",
        "def get_device(device_str=None, verbose=False):\n",
        "    if device_str is None:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    else:\n",
        "        device = torch.device(device_str)\n",
        "    if verbose:\n",
        "        print(f\"Using device: {device}\")\n",
        "    return device\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Model Architectures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# src/models/cnn.py\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, input_channels=3, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(input_channels, 32, 3, 1, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n",
        "        self.fc1 = nn.Linear(128*4*4, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class DCGAN_CNN(nn.Module):\n",
        "    def __init__(self, input_channels=3, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(input_channels, 64, 3, 1, 1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, 1, 1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.fc1 = nn.Linear(128*8*8, 256)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.bn1(self.conv1(x)), 0.2)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.leaky_relu(self.bn2(self.conv2(x)), 0.2)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Data Loaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# src/utils/data_loader.py\n",
        "def seed_everything(seed=123):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def get_mnist_loaders(batch_size=128, val_split=0.1, num_workers=2, pin_memory=True, seed=123):\n",
        "    seed_everything(seed)\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    dataset = datasets.MNIST(root='./data/MNIST', train=True, download=True, transform=transform)\n",
        "    val_size = int(len(dataset) * val_split)\n",
        "    train_size = len(dataset) - val_size\n",
        "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(seed))\n",
        "    test_dataset = datasets.MNIST(root='./data/MNIST', train=False, download=True, transform=transform)\n",
        "    return (\n",
        "        DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory),\n",
        "        DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory),\n",
        "        DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory),\n",
        "    )\n",
        "\n",
        "def get_cifar10_loaders(batch_size=128, val_split=0.1, num_workers=2, pin_memory=True, augment=True, seed=123):\n",
        "    seed_everything(seed)\n",
        "    if augment:\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "        ])\n",
        "    else:\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "        ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "    ])\n",
        "    dataset = datasets.CIFAR10(root='./data/CIFAR10', train=True, download=True, transform=transform_train)\n",
        "    val_size = int(len(dataset) * val_split)\n",
        "    train_size = len(dataset) - val_size\n",
        "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(seed))\n",
        "    test_dataset = datasets.CIFAR10(root='./data/CIFAR10', train=False, download=True, transform=transform_test)\n",
        "    return (\n",
        "        DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory),\n",
        "        DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory),\n",
        "        DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory),\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Training Module (EGEAT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# src/training/train_egeat.py\n",
        "def exact_delta_star(grad, eps, norm='inf'):\n",
        "    if norm == 'inf':\n",
        "        return eps * grad.sign()\n",
        "    g_flat = grad.view(grad.size(0), -1)\n",
        "    if norm == 2:\n",
        "        g_norm = g_flat.norm(p=2, dim=1).view(-1, 1, 1, 1) + 1e-12\n",
        "        return eps * grad / g_norm\n",
        "    if norm == 1:\n",
        "        g_norm = g_flat.abs().max(dim=1)[0].view(-1, 1, 1, 1) + 1e-12\n",
        "        return eps * grad / g_norm\n",
        "    raise ValueError(\"Unsupported norm type.\")\n",
        "\n",
        "def gradient_subspace_penalty(model, x, y, ensemble_models):\n",
        "    if not ensemble_models or len(ensemble_models) == 0:\n",
        "        return 0.0\n",
        "    grads = []\n",
        "    x_req = x.clone().detach().requires_grad_(True)\n",
        "    out = model(x_req)\n",
        "    loss = F.cross_entropy(out, y)\n",
        "    g = torch.autograd.grad(loss, x_req)[0].view(x.size(0), -1)\n",
        "    grads.append(g)\n",
        "    for m in ensemble_models:\n",
        "        m.eval()\n",
        "        x_snap = x.clone().detach().requires_grad_(True)\n",
        "        out_snap = m(x_snap)\n",
        "        loss_snap = F.cross_entropy(out_snap, y)\n",
        "        g_snap = torch.autograd.grad(loss_snap, x_snap)[0].view(x.size(0), -1)\n",
        "        grads.append(g_snap)\n",
        "    L = len(grads)\n",
        "    penalty = 0.0\n",
        "    for i in range(L):\n",
        "        for j in range(i + 1, L):\n",
        "            Gi = grads[i]\n",
        "            Gj = grads[j]\n",
        "            num = (Gi * Gj).sum(dim=1).mean()\n",
        "            den = (Gi.norm(p=2, dim=1) * Gj.norm(p=2, dim=1)).mean() + 1e-12\n",
        "            penalty += num / den\n",
        "    return penalty / (L * (L - 1) / 2)\n",
        "\n",
        "def compute_theta_soup(ensemble_snapshots):\n",
        "    if ensemble_snapshots is None or len(ensemble_snapshots) == 0:\n",
        "        return None\n",
        "    soup = deepcopy(ensemble_snapshots[0])\n",
        "    for k in soup.keys():\n",
        "        for s in ensemble_snapshots[1:]:\n",
        "            soup[k] += s[k]\n",
        "        soup[k] /= len(ensemble_snapshots)\n",
        "    return soup\n",
        "\n",
        "def train_egeat_epoch(model, dataloader, optimizer, device='cuda', lambda_geom=0.1, lambda_soup=0.05, epsilon=8/255, p_norm='inf', ensemble_snapshots=None, use_mixed_precision=False):\n",
        "    model.train()\n",
        "    theta_soup = compute_theta_soup(ensemble_snapshots)\n",
        "    total_loss, total_adv, total_geom, total_soup = 0.0, 0.0, 0.0, 0.0\n",
        "    n_batches = 0\n",
        "    \n",
        "    scaler = torch.cuda.amp.GradScaler() if use_mixed_precision and device.type == 'cuda' else None\n",
        "    \n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x.requires_grad_(True)\n",
        "        \n",
        "        if use_mixed_precision and scaler is not None:\n",
        "            with torch.cuda.amp.autocast():\n",
        "                logits = model(x)\n",
        "                loss_clean = F.cross_entropy(logits, y)\n",
        "                grad_x = torch.autograd.grad(loss_clean, x, create_graph=False)[0]\n",
        "                delta_star = exact_delta_star(grad_x, epsilon, norm=p_norm)\n",
        "                x_adv = torch.clamp(x + delta_star, 0.0, 1.0)\n",
        "                logits_adv = model(x_adv)\n",
        "                L_adv = F.cross_entropy(logits_adv, y)\n",
        "                L_geom = gradient_subspace_penalty(model, x.detach(), y, ensemble_snapshots)\n",
        "                L_soup = 0.0\n",
        "                if theta_soup is not None:\n",
        "                    for p, key in zip(model.parameters(), theta_soup.keys()):\n",
        "                        p_s = theta_soup[key].to(device)\n",
        "                        L_soup += ((p - p_s) ** 2).sum()\n",
        "                L_total = L_adv + lambda_geom * L_geom + lambda_soup * L_soup\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            scaler.scale(L_total).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            logits = model(x)\n",
        "            loss_clean = F.cross_entropy(logits, y)\n",
        "            grad_x = torch.autograd.grad(loss_clean, x, create_graph=False)[0]\n",
        "            delta_star = exact_delta_star(grad_x, epsilon, norm=p_norm)\n",
        "            x_adv = torch.clamp(x + delta_star, 0.0, 1.0)\n",
        "            logits_adv = model(x_adv)\n",
        "            L_adv = F.cross_entropy(logits_adv, y)\n",
        "            L_geom = gradient_subspace_penalty(model, x.detach(), y, ensemble_snapshots)\n",
        "            L_soup = 0.0\n",
        "            if theta_soup is not None:\n",
        "                for p, key in zip(model.parameters(), theta_soup.keys()):\n",
        "                    p_s = theta_soup[key].to(device)\n",
        "                    L_soup += ((p - p_s) ** 2).sum()\n",
        "            L_total = L_adv + lambda_geom * L_geom + lambda_soup * L_soup\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            L_total.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        total_loss += L_total.item()\n",
        "        total_adv += L_adv.item()\n",
        "        total_geom += L_geom if isinstance(L_geom, float) else L_geom.item()\n",
        "        total_soup += L_soup if isinstance(L_soup, float) else L_soup.item()\n",
        "        n_batches += 1\n",
        "    \n",
        "    return {\n",
        "        'loss': total_loss / n_batches,\n",
        "        'adv_loss': total_adv / n_batches,\n",
        "        'geom_loss': total_geom / n_batches,\n",
        "        'soup_loss': total_soup / n_batches\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# src/evaluation/metrics.py\n",
        "def accuracy(model, dataloader, device='cpu'):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            pred = logits.argmax(dim=1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "def ece(model, dataloader, device='cpu', n_bins=15):\n",
        "    model.eval()\n",
        "    confidences = []\n",
        "    accuracies = []\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "            conf, pred = probs.max(dim=1)\n",
        "            confidences.extend(conf.cpu().numpy())\n",
        "            accuracies.extend((pred == y).cpu().numpy())\n",
        "    confidences = np.array(confidences)\n",
        "    accuracies = np.array(accuracies)\n",
        "    bins = np.linspace(0, 1, n_bins + 1)\n",
        "    ece_score = 0.0\n",
        "    for i in range(n_bins):\n",
        "        mask = (confidences > bins[i]) & (confidences <= bins[i+1])\n",
        "        if mask.sum() > 0:\n",
        "            acc_bin = accuracies[mask].mean()\n",
        "            conf_bin = confidences[mask].mean()\n",
        "            ece_score += np.abs(acc_bin - conf_bin) * mask.sum()\n",
        "    return ece_score / len(confidences)\n",
        "\n",
        "# src/evaluation/gradient_similarity.py\n",
        "def compute_input_gradients(model, dataloader, device=None, max_batches=8):\n",
        "    if device is None:\n",
        "        device = next(model.parameters()).device\n",
        "    else:\n",
        "        device = torch.device(device)\n",
        "    model.eval()\n",
        "    ce = torch.nn.CrossEntropyLoss()\n",
        "    grads = []\n",
        "    for i, (x, y) in enumerate(dataloader):\n",
        "        if i >= max_batches:\n",
        "            break\n",
        "        x, y = x.to(device, non_blocking=True).requires_grad_(True), y.to(device, non_blocking=True)\n",
        "        logits = model(x)\n",
        "        loss = ce(logits, y)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        g = x.grad.detach().view(x.size(0), -1).cpu().numpy()\n",
        "        grads.append(g)\n",
        "    return np.concatenate(grads, axis=0)\n",
        "\n",
        "def gradient_subspace_similarity(models, dataloader, device=None, max_batches=8):\n",
        "    if device is None:\n",
        "        device = next(models[0].parameters()).device\n",
        "    else:\n",
        "        device = torch.device(device)\n",
        "    \n",
        "    grad_matrices = []\n",
        "    for model in models:\n",
        "        G = compute_input_gradients(model, dataloader, device, max_batches)\n",
        "        grad_matrices.append(G)\n",
        "    \n",
        "    n_models = len(models)\n",
        "    similarity_matrix = np.zeros((n_models, n_models))\n",
        "    \n",
        "    for i in range(n_models):\n",
        "        for j in range(n_models):\n",
        "            Gi = grad_matrices[i]\n",
        "            Gj = grad_matrices[j]\n",
        "            U_i, _, _ = np.linalg.svd(Gi, full_matrices=False)\n",
        "            U_j, _, _ = np.linalg.svd(Gj, full_matrices=False)\n",
        "            k = min(U_i.shape[1], U_j.shape[1], 50)\n",
        "            U_i_k = U_i[:, :k]\n",
        "            U_j_k = U_j[:, :k]\n",
        "            similarity = np.trace(U_i_k.T @ U_j_k) / k\n",
        "            similarity_matrix[i, j] = similarity\n",
        "    \n",
        "    return similarity_matrix\n",
        "\n",
        "# src/evaluation/ensemble_variance.py\n",
        "def ensemble_variance(models, dataloader, device=None, max_batches=6):\n",
        "    if device is None:\n",
        "        device = next(models[0].parameters()).device\n",
        "    else:\n",
        "        device = torch.device(device)\n",
        "    \n",
        "    ce = torch.nn.CrossEntropyLoss(reduction='none')\n",
        "    variances = []\n",
        "    Kvals = list(range(1, len(models) + 1))\n",
        "    \n",
        "    for k in Kvals:\n",
        "        batch_vars = []\n",
        "        for i, (X, y) in enumerate(dataloader):\n",
        "            if i >= max_batches:\n",
        "                break\n",
        "            per_losses = []\n",
        "            X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "            for m in models[:k]:\n",
        "                m.eval()\n",
        "                with torch.no_grad():\n",
        "                    l = ce(m(X), y).cpu().numpy()\n",
        "                    per_losses.append(l)\n",
        "            per_losses = np.stack(per_losses, axis=0)\n",
        "            batch_vars.append(np.mean(np.var(per_losses, axis=0)))\n",
        "        variances.append(np.mean(batch_vars))\n",
        "    \n",
        "    return Kvals, variances\n",
        "\n",
        "# src/evaluation/loss_landscape.py\n",
        "def param_vector(model):\n",
        "    return torch.nn.utils.parameters_to_vector(model.parameters()).detach().clone()\n",
        "\n",
        "def set_param_vector(model, vec):\n",
        "    torch.nn.utils.vector_to_parameters(vec, model.parameters())\n",
        "\n",
        "def loss_on_vector(model, vec, X, y, device='cpu'):\n",
        "    set_param_vector(model, vec)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(X.to(device))\n",
        "        loss = torch.nn.functional.cross_entropy(logits, y.to(device)).item()\n",
        "    return loss\n",
        "\n",
        "def scan_1d_loss(model, dataloader, device='cpu', grid_n=21, radius=1.0):\n",
        "    Xs, ys = [], []\n",
        "    for i, (X, y) in enumerate(dataloader):\n",
        "        Xs.append(X); ys.append(y)\n",
        "        if i >= 2: break\n",
        "    X, y = torch.cat(Xs, dim=0), torch.cat(ys, dim=0)\n",
        "    base = param_vector(model).to(device)\n",
        "    D = base.numel()\n",
        "    direction = torch.randn(D, device=device); direction /= direction.norm()\n",
        "    alphas = np.linspace(-radius, radius, grid_n)\n",
        "    losses = np.zeros(grid_n)\n",
        "    for i, a in enumerate(alphas):\n",
        "        vec = base + a*direction\n",
        "        losses[i] = loss_on_vector(model, vec, X, y, device=device)\n",
        "    set_param_vector(model, base)\n",
        "    return alphas, losses\n",
        "\n",
        "def scan_2d_loss(model, dataloader, device='cpu', grid_n=21, radius=1.0):\n",
        "    Xs, ys = [], []\n",
        "    for i, (X, y) in enumerate(dataloader):\n",
        "        Xs.append(X); ys.append(y)\n",
        "        if i >= 2: break\n",
        "    X, y = torch.cat(Xs, dim=0), torch.cat(ys, dim=0)\n",
        "    base = param_vector(model).to(device)\n",
        "    D = base.numel()\n",
        "    dir_a = torch.randn(D, device=device); dir_a /= dir_a.norm()\n",
        "    dir_b = torch.randn(D, device=device); dir_b -= (dir_b.dot(dir_a))*dir_a; dir_b /= dir_b.norm()\n",
        "    alphas = np.linspace(-radius, radius, grid_n)\n",
        "    betas = np.linspace(-radius, radius, grid_n)\n",
        "    losses = np.zeros((grid_n, grid_n))\n",
        "    for i, a in enumerate(alphas):\n",
        "        for j, b in enumerate(betas):\n",
        "            vec = base + a*dir_a + b*dir_b\n",
        "            losses[i,j] = loss_on_vector(model, vec, X, y, device=device)\n",
        "    set_param_vector(model, base)\n",
        "    return alphas, betas, losses\n",
        "\n",
        "# src/evaluation/transferability.py\n",
        "def fgsm_attack(model, x, y, epsilon=8/255):\n",
        "    x.requires_grad_(True)\n",
        "    logits = model(x)\n",
        "    loss = F.cross_entropy(logits, y)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    x_adv = x + epsilon * x.grad.sign()\n",
        "    x_adv = torch.clamp(x_adv, 0, 1)\n",
        "    return x_adv.detach()\n",
        "\n",
        "def transferability_matrix(models, dataloader, device=None, max_batches=10, epsilon=8/255, alpha=2/255, iters=10):\n",
        "    if device is None:\n",
        "        device = next(models[0].parameters()).device\n",
        "    else:\n",
        "        device = torch.device(device)\n",
        "    \n",
        "    n_models = len(models)\n",
        "    P = np.zeros((n_models, n_models))\n",
        "    \n",
        "    for src_idx in range(n_models):\n",
        "        src_model = models[src_idx]\n",
        "        src_model.eval()\n",
        "        \n",
        "        for tgt_idx in range(n_models):\n",
        "            tgt_model = models[tgt_idx]\n",
        "            tgt_model.eval()\n",
        "            \n",
        "            correct_orig = 0\n",
        "            correct_adv = 0\n",
        "            total = 0\n",
        "            \n",
        "            for i, (x, y) in enumerate(dataloader):\n",
        "                if i >= max_batches:\n",
        "                    break\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    pred_orig = tgt_model(x).argmax(dim=1)\n",
        "                    correct_orig += (pred_orig == y).sum().item()\n",
        "                \n",
        "                x_adv = fgsm_attack(src_model, x, y, epsilon)\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    pred_adv = tgt_model(x_adv).argmax(dim=1)\n",
        "                    correct_adv += (pred_adv == y).sum().item()\n",
        "                \n",
        "                total += y.size(0)\n",
        "            \n",
        "            acc_orig = correct_orig / total\n",
        "            acc_adv = correct_adv / total\n",
        "            transfer_rate = 1.0 - (acc_adv / acc_orig) if acc_orig > 0 else 0.0\n",
        "            P[src_idx, tgt_idx] = transfer_rate\n",
        "    \n",
        "    return P\n",
        "\n",
        "# src/evaluation/adversarial_images.py\n",
        "def generate_adv_examples(src_model, tgt_model, dataloader, device=None, n_samples=16, epsilon=8/255, alpha=2/255, iters=10):\n",
        "    if device is None:\n",
        "        device = next(src_model.parameters()).device\n",
        "    else:\n",
        "        device = torch.device(device)\n",
        "    \n",
        "    src_model.eval()\n",
        "    samples = []\n",
        "    \n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x_adv = fgsm_attack(src_model, x, y, epsilon)\n",
        "        \n",
        "        for i in range(min(n_samples - len(samples), x.size(0))):\n",
        "            orig_img = x[i].cpu().numpy()\n",
        "            adv_img = x_adv[i].cpu().numpy()\n",
        "            samples.append((orig_img, adv_img))\n",
        "        \n",
        "        if len(samples) >= n_samples:\n",
        "            break\n",
        "    \n",
        "    return samples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# src/utils/viz_utils.py\n",
        "def ensure_dir(path):\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "\n",
        "def save_heatmap(mat, path, title=\"\", cmap=\"viridis\"):\n",
        "    ensure_dir(path)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(mat, cmap=cmap, square=True, annot=True, fmt='.3f')\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def save_contour(alphas, betas, losses, path, title=\"Loss surface\"):\n",
        "    ensure_dir(path)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.contourf(betas, alphas, losses, levels=50, cmap=\"viridis\")\n",
        "    plt.colorbar()\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.xlabel(\"Beta Direction\", fontsize=12)\n",
        "    plt.ylabel(\"Alpha Direction\", fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def save_image_grid(imgs, path, nrow=8, normalize=True, title=None):\n",
        "    ensure_dir(path)\n",
        "    N = len(imgs)\n",
        "    cols = nrow\n",
        "    rows = (N + cols - 1) // cols\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 1.5, rows * 1.5))\n",
        "    if rows == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    axes = axes.flatten()\n",
        "    for i in range(len(axes)):\n",
        "        axes[i].axis('off')\n",
        "        if i < N:\n",
        "            img = imgs[i]\n",
        "            if normalize:\n",
        "                img = (img + 1) / 2\n",
        "            if len(img.shape) == 3 and img.shape[0] == 3:\n",
        "                img = np.transpose(img, (1, 2, 0))\n",
        "            elif len(img.shape) == 3 and img.shape[0] == 1:\n",
        "                img = img[0]\n",
        "            axes[i].imshow(np.clip(img, 0, 1), cmap='gray' if len(img.shape) == 2 else None)\n",
        "    if title:\n",
        "        plt.suptitle(title, fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def save_line(xs, ys, path, xlabel=\"\", ylabel=\"\", title=\"\"):\n",
        "    ensure_dir(path)\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(xs, ys, marker='o', linewidth=2, markersize=6)\n",
        "    plt.xlabel(xlabel, fontsize=12)\n",
        "    plt.ylabel(ylabel, fontsize=12)\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# Display functions for Colab\n",
        "def display_heatmap(mat, title=\"\", cmap=\"viridis\"):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(mat, cmap=cmap, square=True, annot=True, fmt='.3f')\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def display_line(xs, ys, xlabel=\"\", ylabel=\"\", title=\"\"):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(xs, ys, marker='o', linewidth=2, markersize=6)\n",
        "    plt.xlabel(xlabel, fontsize=12)\n",
        "    plt.ylabel(ylabel, fontsize=12)\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def display_contour(alphas, betas, losses, title=\"Loss surface\"):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.contourf(betas, alphas, losses, levels=50, cmap=\"viridis\")\n",
        "    plt.colorbar()\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.xlabel(\"Beta Direction\", fontsize=12)\n",
        "    plt.ylabel(\"Alpha Direction\", fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def display_image_grid(imgs, nrow=8, normalize=True, title=None):\n",
        "    N = len(imgs)\n",
        "    cols = nrow\n",
        "    rows = (N + cols - 1) // cols\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 1.5, rows * 1.5))\n",
        "    if rows == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    axes = axes.flatten()\n",
        "    for i in range(len(axes)):\n",
        "        axes[i].axis('off')\n",
        "        if i < N:\n",
        "            img = imgs[i]\n",
        "            if normalize:\n",
        "                img = (img + 1) / 2\n",
        "            if len(img.shape) == 3 and img.shape[0] == 3:\n",
        "                img = np.transpose(img, (1, 2, 0))\n",
        "            elif len(img.shape) == 3 and img.shape[0] == 1:\n",
        "                img = img[0]\n",
        "            axes[i].imshow(np.clip(img, 0, 1), cmap='gray' if len(img.shape) == 2 else None)\n",
        "    if title:\n",
        "        plt.suptitle(title, fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Run Complete Experiment\n",
        "\n",
        "This section runs the full EGEAT experiment pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure experiment\n",
        "config = ExperimentConfig(\n",
        "    experiment_name='egeat_colab',\n",
        "    seed=42,\n",
        "    device=None,  # Auto-detect\n",
        "    save_dir='results',\n",
        "    training=TrainingConfig(\n",
        "        batch_size=128,\n",
        "        learning_rate=2e-4,\n",
        "        epochs=5,  # Reduced for Colab demo\n",
        "        lambda_geom=0.1,\n",
        "        lambda_soup=0.05,\n",
        "        epsilon=8/255,\n",
        "        use_mixed_precision=False,\n",
        "        num_workers=2\n",
        "    ),\n",
        "    model=ModelConfig(\n",
        "        model_type='SimpleCNN',\n",
        "        input_channels=3,\n",
        "        num_classes=10,\n",
        "        ensemble_size=3  # Reduced for Colab demo\n",
        "    ),\n",
        "    data=DataConfig(\n",
        "        dataset='cifar10',\n",
        "        val_split=0.1,\n",
        "        augment=True\n",
        "    ),\n",
        "    evaluation=EvaluationConfig(\n",
        "        max_batches=10,\n",
        "        n_bins_ece=15,\n",
        "        loss_landscape_grid_n=21,\n",
        "        loss_landscape_radius=1.0\n",
        "    )\n",
        ")\n",
        "\n",
        "# Set up directories\n",
        "os.makedirs(config.save_dir, exist_ok=True)\n",
        "os.makedirs(os.path.join(config.save_dir, 'figures'), exist_ok=True)\n",
        "os.makedirs(os.path.join(config.save_dir, 'adv_images'), exist_ok=True)\n",
        "os.makedirs(os.path.join(config.save_dir, 'checkpoints'), exist_ok=True)\n",
        "\n",
        "# Set seed\n",
        "torch.manual_seed(config.seed)\n",
        "torch.cuda.manual_seed_all(config.seed)\n",
        "np.random.seed(config.seed)\n",
        "import random\n",
        "random.seed(config.seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Get device\n",
        "device = get_device(config.device, verbose=True)\n",
        "\n",
        "print(f\"\\nExperiment Configuration:\")\n",
        "print(f\"  Dataset: {config.data.dataset}\")\n",
        "print(f\"  Model: {config.model.model_type}\")\n",
        "print(f\"  Ensemble Size: {config.model.ensemble_size}\")\n",
        "print(f\"  Epochs: {config.training.epochs}\")\n",
        "print(f\"  Batch Size: {config.training.batch_size}\")\n",
        "print(f\"  Lambda Geom: {config.training.lambda_geom}\")\n",
        "print(f\"  Lambda Soup: {config.training.lambda_soup}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "print(f\"\\nLoading {config.data.dataset} dataset...\")\n",
        "if config.data.dataset.lower() == 'cifar10':\n",
        "    train_loader, val_loader, test_loader = get_cifar10_loaders(\n",
        "        batch_size=config.training.batch_size,\n",
        "        val_split=config.data.val_split,\n",
        "        num_workers=config.training.num_workers,\n",
        "        pin_memory=config.training.pin_memory,\n",
        "        augment=config.data.augment,\n",
        "        seed=config.seed\n",
        "    )\n",
        "    config.model.input_channels = 3\n",
        "    config.model.num_classes = 10\n",
        "elif config.data.dataset.lower() == 'mnist':\n",
        "    train_loader, val_loader, test_loader = get_mnist_loaders(\n",
        "        batch_size=config.training.batch_size,\n",
        "        val_split=config.data.val_split,\n",
        "        num_workers=config.training.num_workers,\n",
        "        pin_memory=config.training.pin_memory,\n",
        "        seed=config.seed\n",
        "    )\n",
        "    config.model.input_channels = 1\n",
        "    config.model.num_classes = 10\n",
        "else:\n",
        "    raise ValueError(f\"Unsupported dataset: {config.data.dataset}\")\n",
        "\n",
        "print(f\"Dataset loaded. Train batches: {len(train_loader)}, Val batches: {len(val_loader)}, Test batches: {len(test_loader)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize ensemble models\n",
        "print(f\"\\nInitializing {config.model.ensemble_size} {config.model.model_type} models...\")\n",
        "models = []\n",
        "model_class = SimpleCNN if config.model.model_type == 'SimpleCNN' else DCGAN_CNN\n",
        "\n",
        "for i in range(config.model.ensemble_size):\n",
        "    model = model_class(\n",
        "        input_channels=config.model.input_channels,\n",
        "        num_classes=config.model.num_classes\n",
        "    )\n",
        "    model = model.to(device)\n",
        "    models.append(model)\n",
        "\n",
        "print(f\"Initialized {len(models)} models on {device}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
